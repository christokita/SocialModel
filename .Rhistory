scale_x_discrete(drop = FALSE) +
scale_y_discrete(drop = FALSE) +
scale_fill_gradientn(colours = rev(brewer.pal(9,"RdYlBu")), na.value = "white", limit = c(-1.5, 1.5), oob = squish) +
theme(
# Rotate the x-axis lables so they are legible
axis.text.x = element_text(angle = 270, hjust = 0, size = 2),
axis.text.y = element_text(size = 2),
# Force the plot into a square aspect ratio
aspect.ratio = 1,
# Hide the legend (optional)
legend.position = "none")
ggplot(plot_data, aes(x = from, y = to, fill = weight)) +
geom_raster() +
theme_bw() +
# Because we need the x and y axis to display every node,
# not just the nodes that have connections to each other,
# make sure that ggplot does not drop unused factor levels
scale_x_discrete(drop = FALSE) +
scale_y_discrete(drop = FALSE) +
scale_fill_gradientn(colours = rev(brewer.pal(9,"RdYlBu")), na.value = "white", limit = c(-1, 1), oob = squish) +
theme(
# Rotate the x-axis lables so they are legible
axis.text.x = element_text(angle = 270, hjust = 0, size = 2),
axis.text.y = element_text(size = 2),
# Force the plot into a square aspect ratio
aspect.ratio = 1,
# Hide the legend (optional)
legend.position = "none")
ggplot(plot_data, aes(x = from, y = to, fill = weight)) +
geom_raster() +
theme_bw() +
# Because we need the x and y axis to display every node,
# not just the nodes that have connections to each other,
# make sure that ggplot does not drop unused factor levels
scale_x_discrete(drop = FALSE) +
scale_y_discrete(drop = FALSE) +
scale_fill_gradientn(colours = rev(brewer.pal(9,"RdYlBu")), na.value = "white", limit = c(-1.5, 1.5), oob = squish) +
theme(
# Rotate the x-axis lables so they are legible
axis.text.x = element_text(angle = 270, hjust = 0, size = 2),
axis.text.y = element_text(size = 2),
# Force the plot into a square aspect ratio
aspect.ratio = 1,
# Hide the legend (optional)
legend.position = "none")
?scale_fill_gradient2
# scale_fill_gradientn(colours = rev(brewer.pal(9,"RdYlBu")), na.value = "white", limit = c(-1.5, 1.5), oob = squish) +
scale_fill_gradient2(colours = rev(low = "white", mid = "#fee090", high = "#d73027" limit = c(-1.5, 1.5), oob = squish) +
ggplot(plot_data, aes(x = from, y = to, fill = weight)) +
geom_raster() +
theme_bw() +
# Because we need the x and y axis to display every node,
# not just the nodes that have connections to each other,
# make sure that ggplot does not drop unused factor levels
scale_x_discrete(drop = FALSE) +
scale_y_discrete(drop = FALSE) +
# scale_fill_gradientn(colours = rev(brewer.pal(9,"RdYlBu")), na.value = "white", limit = c(-1.5, 1.5), oob = squish) +
scale_fill_gradient2(low = "white", mid = "#fee090", high = "#d73027" limit = c(-1.5, 1.5), oob = squish) +
theme(
# Rotate the x-axis lables so they are legible
axis.text.x = element_text(angle = 270, hjust = 0, size = 2),
axis.text.y = element_text(size = 2),
# Force the plot into a square aspect ratio
aspect.ratio = 1,
# Hide the legend (optional)
legend.position = "none")
ggplot(plot_data, aes(x = from, y = to, fill = weight)) +
geom_raster() +
theme_bw() +
# Because we need the x and y axis to display every node,
# not just the nodes that have connections to each other,
# make sure that ggplot does not drop unused factor levels
scale_x_discrete(drop = FALSE) +
scale_y_discrete(drop = FALSE) +
# scale_fill_gradientn(colours = rev(brewer.pal(9,"RdYlBu")), na.value = "white", limit = c(-1.5, 1.5), oob = squish) +
scale_fill_gradient2(low = "white", mid = "#fee090", high = "#d73027", limit = c(-1.5, 1.5), oob = squish) +
theme(
# Rotate the x-axis lables so they are legible
axis.text.x = element_text(angle = 270, hjust = 0, size = 2),
axis.text.y = element_text(size = 2),
# Force the plot into a square aspect ratio
aspect.ratio = 1,
# Hide the legend (optional)
legend.position = "none")
ggplot(plot_data, aes(x = from, y = to, fill = weight)) +
geom_raster() +
theme_bw() +
# Because we need the x and y axis to display every node,
# not just the nodes that have connections to each other,
# make sure that ggplot does not drop unused factor levels
scale_x_discrete(drop = FALSE) +
scale_y_discrete(drop = FALSE) +
# scale_fill_gradientn(colours = rev(brewer.pal(9,"RdYlBu")), na.value = "white", limit = c(-1.5, 1.5), oob = squish) +
scale_fill_gradient2(low = "white", mid = "#fee090", high = "#d73027", limit = c(-1.5, 1.5), oob = squish, na.value = "white") +
theme(
# Rotate the x-axis lables so they are legible
axis.text.x = element_text(angle = 270, hjust = 0, size = 2),
axis.text.y = element_text(size = 2),
# Force the plot into a square aspect ratio
aspect.ratio = 1,
# Hide the legend (optional)
legend.position = "none")
ggplot(plot_data, aes(x = from, y = to, fill = weight)) +
geom_raster() +
theme_bw() +
# Because we need the x and y axis to display every node,
# not just the nodes that have connections to each other,
# make sure that ggplot does not drop unused factor levels
scale_x_discrete(drop = FALSE) +
scale_y_discrete(drop = FALSE) +
# scale_fill_gradientn(colours = rev(brewer.pal(9,"RdYlBu")), na.value = "white", limit = c(-1.5, 1.5), oob = squish) +
scale_fill_gradientn(colours = rev(brewer.pal(9,"BuPu")), na.value = "white", limit = c(-1.5, 1.5), oob = squish) +
theme(
# Rotate the x-axis lables so they are legible
axis.text.x = element_text(angle = 270, hjust = 0, size = 2),
axis.text.y = element_text(size = 2),
# Force the plot into a square aspect ratio
aspect.ratio = 1,
# Hide the legend (optional)
legend.position = "none")
ggplot(plot_data, aes(x = from, y = to, fill = weight)) +
geom_raster() +
theme_bw() +
# Because we need the x and y axis to display every node,
# not just the nodes that have connections to each other,
# make sure that ggplot does not drop unused factor levels
scale_x_discrete(drop = FALSE) +
scale_y_discrete(drop = FALSE) +
# scale_fill_gradientn(colours = rev(brewer.pal(9,"RdYlBu")), na.value = "white", limit = c(-1.5, 1.5), oob = squish) +
scale_fill_gradientn(colours = brewer.pal(9,"BuPu"), na.value = "white", limit = c(-1.5, 1.5), oob = squish) +
theme(
# Rotate the x-axis lables so they are legible
axis.text.x = element_text(angle = 270, hjust = 0, size = 2),
axis.text.y = element_text(size = 2),
# Force the plot into a square aspect ratio
aspect.ratio = 1,
# Hide the legend (optional)
legend.position = "none")
ggplot(plot_data, aes(x = from, y = to, fill = weight)) +
geom_raster() +
theme_bw() +
# Because we need the x and y axis to display every node,
# not just the nodes that have connections to each other,
# make sure that ggplot does not drop unused factor levels
scale_x_discrete(drop = FALSE) +
scale_y_discrete(drop = FALSE) +
# scale_fill_gradientn(colours = rev(brewer.pal(9,"RdYlBu")), na.value = "white", limit = c(-1.5, 1.5), oob = squish) +
scale_fill_gradientn(colours = brewer.pal(9,"YlGn"), na.value = "white", limit = c(-1.5, 1.5), oob = squish) +
theme(
# Rotate the x-axis lables so they are legible
axis.text.x = element_text(angle = 270, hjust = 0, size = 2),
axis.text.y = element_text(size = 2),
# Force the plot into a square aspect ratio
aspect.ratio = 1,
# Hide the legend (optional)
legend.position = "none")
BuPu
ggplot(plot_data, aes(x = from, y = to, fill = weight)) +
geom_raster() +
theme_bw() +
# Because we need the x and y axis to display every node,
# not just the nodes that have connections to each other,
# make sure that ggplot does not drop unused factor levels
scale_x_discrete(drop = FALSE) +
scale_y_discrete(drop = FALSE) +
# scale_fill_gradientn(colours = rev(brewer.pal(9,"RdYlBu")), na.value = "white", limit = c(-1.5, 1.5), oob = squish) +
scale_fill_gradientn(colours = brewer.pal(9,"BuPu"), na.value = "white", limit = c(-1.5, 1.5), oob = squish) +
theme(
# Rotate the x-axis lables so they are legible
axis.text.x = element_text(angle = 270, hjust = 0, size = 2),
axis.text.y = element_text(size = 2),
# Force the plot into a square aspect ratio
aspect.ratio = 1,
# Hide the legend (optional)
legend.position = "none")
rm(list = ls())
source("scripts/__Util__MASTER.R")
library(RColorBrewer)
library(scales)
library(igraph)
filename <- "Sigma0.0-Eps0.01--Bias1.1"
# Cutoff for threshold ratio to allow easier plotting
ThreshCutoffValue <- 10
ThreshCutoffReplacement <- Inf
ThreshCutoffReplacementColor <- 10
####################
# Load data
####################
# Load social
load("output/Rdata/Sigma0.05-Epsilon0.01-Bias1.1.Rdata")
soc_graphs <- unlist(groups_graphs, recursive = FALSE)
soc_threshMat <- unlist(groups_thresh, recursive = FALSE)
soc_actMat <- unlist(groups_taskDist, recursive = FALSE)
social_graphs <- lapply(1:length(soc_graphs), function(i) {
# Calculated degree
degree <- rowSums(soc_graphs[[i]])
degree <- as.data.frame(degree)
degree$Id <- row.names(degree)
# Calculate thresholds
thresh <- soc_threshMat[[i]] %>%
as.data.frame(.) %>%
mutate(ThreshRatio = log(Thresh1 / Thresh2),
Id = row.names(.))
thresh$ThreshRatio[thresh$ThreshRatio > ThreshCutoffValue] <- ThreshCutoffReplacement
thresh$ThreshRatio[thresh$ThreshRatio < -ThreshCutoffValue] <- -ThreshCutoffReplacement
thresh$ThreshRatioColor <- thresh$ThreshRatio
thresh$ThreshRatioColor[thresh$ThreshRatio > ThreshCutoffValue] <- ThreshCutoffReplacementColor
thresh$ThreshRatioColor[thresh$ThreshRatio < -ThreshCutoffValue] <- -ThreshCutoffReplacementColor
# Calculate actibity
activity <- soc_actMat[[i]] %>%
as.data.frame(.) %>%
mutate(ActRatio = log(Task1 / Task2),
ActTotal = Task1 + Task2,
Id = row.names(.))
# Merge and return
mergedNodes <- merge(degree, thresh)
mergedNodes <- merge(mergedNodes, activity)
return(mergedNodes)
})
social_graphs <- do.call("rbind", social_graphs)
# Testing whatever here
look <- soc_graphs[[230]]
diag(look) <- NA
look <- scale(look)
g <- soc_graphs[[230]]
diag(g) <- NA
g <- scale(g)
g <- graph_from_adjacency_matrix(g, mode = c("directed"), weighted = TRUE, diag = TRUE)
test <- spinglass.community(g, weights = E(g)$weight)
V(g)$membership <- test$membership
threshMat <- groups_thresh[[230]]
soc_threshMat[[230]]
threshMat <- soc_threshMat[[230]]
thresh <- soc_threshMat[[230]]
V(g)$ThreshRatio <- log(thresh$Thresh1 / thresh$Thresh2)
thresh$Thresh1 / thresh$Thresh2
thresh
thresh <- as.data.frame(soc_threshMat[[230]])
V(g)$ThreshRatio <- log(thresh$Thresh1 / thresh$Thresh2)
# Determine a community for each edge. If two nodes belong to the
# same community, label the edge with that community. If not,
# the edge community value is 'NA'
edge_list <- get.data.frame(g, what = "edges") %>%
inner_join(node_list %>% select(name, membership), by = c("from" = "name")) %>%
inner_join(node_list %>% select(name, membership), by = c("to" = "name")) %>%
mutate(group = ifelse(membership.x == membership.y, membership.x, NA) %>% factor())
name_order <- (node_list %>% arrange(ThreshRatio))$name
node_list <- get.data.frame(g, what = "vertices")
# Determine a community for each edge. If two nodes belong to the
# same community, label the edge with that community. If not,
# the edge community value is 'NA'
edge_list <- get.data.frame(g, what = "edges") %>%
inner_join(node_list %>% select(name, membership), by = c("from" = "name")) %>%
inner_join(node_list %>% select(name, membership), by = c("to" = "name")) %>%
mutate(group = ifelse(membership.x == membership.y, membership.x, NA) %>% factor())
name_order <- (node_list %>% arrange(ThreshRatio))$name
name_order
plot_data <- edge_list %>% mutate(
to = factor(to, levels = name_order),
from = factor(from, levels = name_order))
ggplot(plot_data, aes(x = from, y = to, fill = weight)) +
geom_raster() +
theme_bw() +
# Because we need the x and y axis to display every node,
# not just the nodes that have connections to each other,
# make sure that ggplot does not drop unused factor levels
scale_x_discrete(drop = FALSE) +
scale_y_discrete(drop = FALSE) +
# scale_fill_gradientn(colours = rev(brewer.pal(9,"RdYlBu")), na.value = "white", limit = c(-1.5, 1.5), oob = squish) +
scale_fill_gradientn(colours = brewer.pal(9,"BuPu"), na.value = "white", limit = c(-1.5, 1.5), oob = squish) +
theme(
# Rotate the x-axis lables so they are legible
axis.text.x = element_text(angle = 270, hjust = 0, size = 2),
axis.text.y = element_text(size = 2),
# Force the plot into a square aspect ratio
aspect.ratio = 1,
# Hide the legend (optional)
legend.position = "none")
ggplot(plot_data, aes(x = from, y = to, fill = weight)) +
geom_raster() +
theme_bw() +
# Because we need the x and y axis to display every node,
# not just the nodes that have connections to each other,
# make sure that ggplot does not drop unused factor levels
scale_x_discrete(drop = FALSE) +
scale_y_discrete(drop = FALSE) +
# scale_fill_gradientn(colours = rev(brewer.pal(9,"RdYlBu")), na.value = "white", limit = c(-1.5, 1.5), oob = squish) +
scale_fill_gradientn(colours = brewer.pal(9,"BuPu"), na.value = "white", limit = c(-1, 1), oob = squish) +
theme(
# Rotate the x-axis lables so they are legible
axis.text.x = element_text(angle = 270, hjust = 0, size = 2),
axis.text.y = element_text(size = 2),
# Force the plot into a square aspect ratio
aspect.ratio = 1,
# Hide the legend (optional)
legend.position = "none")
#############################################################################
rm(list = ls())
source("scripts/__Util__MASTER.R")
####################
# Set global variables
####################
# Initial paramters: Free to change
# Base parameters
Ns             <- c(10) #vector of number of individuals to simulate
m              <- 2 #number of tasks
gens           <- 10000 #number of generations to run simulation
corrStep       <- 200 #number of time steps for calculation of correlation
reps           <- 1 #number of replications per simulation (for ensemble)
# Threshold Parameters
ThreshM        <- rep(10, m) #population threshold means
ThreshSD       <- ThreshM * 0.0 #population threshold standard deviations
InitialStim    <- rep(0, m) #intital vector of stimuli
deltas         <- rep(0.6, m) #vector of stimuli increase rates
alpha          <- m #efficiency of task performance
quitP          <- 0.2 #probability of quitting task once active
# Social Network Parameters
epsilon        <- 0.0003 #relative weighting of social interactions for adjusting thresholds
q              <- 1.1 #probability of interacting with individual in same state relative to others
####################
# Run simulation multiple times
####################
# Prep meta-lists for collection of group size simulations
groups_taskDist  <- list()
groups_taskCorr  <- list()
groups_taskStep  <- list()
groups_taskTally <- list()
groups_stim      <- list()
groups_thresh    <- list()
groups_entropy   <- list()
groups_graphs    <- list()
# Loop through group sizes
for (i in 1:length(Ns)) {
# Set group size
n <- Ns[i]
# Prep lists for collection of simulation outputs
ens_taskDist  <- list()
ens_taskCorr  <- list()
ens_taskStep  <- list()
ens_taskTally <- list()
ens_entropy   <- list()
ens_stim      <- list()
ens_thresh    <- list()
ens_graphs    <- list()
# Run Simulations
for (sim in 1:reps) {
####################
# Seed structures and intial matrices
####################
# Set initial probability matrix (P_g)
P_g <- matrix(data = rep(0, n * m), ncol = m)
# Seed task (external) stimuli
stimMat <- seedStimuls(InitialSVector = InitialStim,
gens = gens)
# Seed internal thresholds
threshMat <- seedThresholds(n = n,
m = m,
ThresholdMeans = ThreshM,
ThresholdSDs = ThreshSD)
# Start task performance
X_g <- matrix(data = rep(0, length(P_g)), ncol = ncol(P_g))
# Create cumulative task performance matrix
X_tot <- X_g
# Create cumulative adjacency matrix
g_tot <-  matrix(data = rep(0, n * n), ncol = n)
colnames(g_tot) <- paste0("v-", 1:n)
rownames(g_tot) <- paste0("v-", 1:n)
# Prep correlation step matrix
X_prev <- matrix(data = rep(0, n * m), ncol = m)
X_prevTot <- matrix(data = rep(0, n * m), ncol = m)
taskCorr <- list()
taskStep <- list()
taskTally <- list()
####################
# Simulate
####################
# Run simulation
for (t in 1:gens) {
# Update stimuli
for (j in 1:ncol(stimMat)) {
# update stim
stimMat[t + 1, j] <- globalStimUpdate(stimulus = stimMat[t, j],
delta = deltas[j],
alpha = alpha,
Ni = sum(X_g[ , j]),
n = n)
}
# Calculate task demand based on global stimuli
P_g <- calcThresholdDetermMat(TimeStep = t + 1, # first row is generation 0
ThresholdMatrix = threshMat,
StimulusMatrix = stimMat)
# Update task performance
X_g <- updateTaskPerformance(P_sub_g    = P_g,
TaskMat    = X_g,
QuitProb   = quitP)
# Update social network
g_adj <- temporalNetwork(X_sub_g = X_g,
bias = q)
g_tot <- g_tot + g_adj
# Adjust thresholds
threshMat <- adjustThresholdsSocial(SocialNetwork = g_adj,
ThresholdMatrix = threshMat,
X_sub_g = X_g,
epsilon = epsilon)
# Capture current task performance tally
tally <- matrix(c(t, colSums(X_g)), ncol = ncol(X_g) + 1)
colnames(tally) <- c("t", colnames(X_g))
tally <- transform(tally, Inactive = n - sum(X_g), n = n, replicate = sim)
taskTally[[t]] <- tally
# Update total task performance profile
X_tot <- X_tot + X_g
# Create time step for correlation
if (t %% corrStep == 0) {
# Get tasks performance in correlation step
X_step <- X_tot - X_prevTot
# Add to ensemble list of task steps
taskStep[[t / corrStep]] <- X_step
# Calculate rank correlation if it is not the first step
if(sum(X_prev) != 0) {
# Normalize
stepNorm <- X_step / rowSums(X_step)
prevNorm <- X_prev / rowSums(X_prev)
# Calculate ranks
step_ranks <- calculateTaskRank(TaskStepMat = X_step)
prev_ranks <- calculateTaskRank(TaskStepMat = X_prev)
# Calculate Correlation
rankCorr <- cor(prev_ranks, step_ranks, method = "spearman")
# Put in list
taskCorr[[(t / corrStep) - 1]] <- diag(rankCorr)
names(taskCorr)[(t / corrStep) - 1] <- paste0("Gen", t)
}
# Update previous step total matrix
X_prevTot <- X_tot
# Update previous step total matrix
X_prev <- X_step
}
}
# Calculate Entropy
entropy <- mutualEntropy(TotalStateMat = X_tot)
entropy <- transform(entropy, n = n, replicate = sim)
# Calculate total task distribution
# totalTaskDist <- X_tot / rowSums(X_tot)
totalTaskDist <- X_tot / gens
totalTaskDist <- transform(totalTaskDist, Inactive = gens - rowSums(X_tot), n = n, replicate = sim)
# Create tasktally table
taskTally <- do.call("rbind", taskTally)
# Create tasktally table
stimMat <- transform(stimMat, n = n, replicate = sim)
# Create tasktally table
taskCorr <- transform(taskCorr, replicate = sim)
# Add total task distributions, entropy values, and graphs to lists
ens_taskDist[[sim]]  <- totalTaskDist
ens_entropy[[sim]]   <- entropy
ens_taskCorr[[sim]]  <- taskCorr
ens_taskTally[[sim]] <- taskTally
ens_taskStep[[sim]]  <- taskStep
ens_stim[[sim]]      <- stimMat
ens_thresh[[sim]]    <- threshMat
ens_graphs[[sim]]    <- g_tot / gens
# Print simulation completed
print(paste0("DONE: N = ", n, ", Simulation ", sim))
}
# Calculate mean correlation for each n
runCorrs <- lapply(ens_taskCorr, function(x) {
# Unlist
runs <- do.call("rbind", x)
replicate <- runs[nrow(runs), ]
replicate <- unique(replicate)
runs <- runs[-nrow(runs), ]
# Calculate mean
runMean <- matrix(data = rep(NA, m), ncol =  m)
for (column in 1:m) {
runMean[ , column] <- mean(runs[ , column], na.rm = TRUE)
}
runMean <- cbind(runMean, replicate)
colnames(runMean) <- c(paste0("Task", 1:m), "replicate")
return(runMean)
})
runCorrs <- do.call("rbind", runCorrs)
runCorrs <- transform(runCorrs, n = n)
# Add to list of lists
groups_taskDist[[i]]  <- ens_taskDist
groups_taskCorr[[i]]  <- runCorrs
groups_taskStep[[i]]  <- ens_taskStep
groups_taskTally[[i]] <- ens_taskTally
groups_stim[[i]]      <- ens_stim
groups_thresh[[i]]    <- ens_thresh
groups_entropy[[i]]   <- ens_entropy
groups_graphs[[i]]    <- ens_graphs
}
# trim out correlations for group size 1
if(1 %in% Ns) {
groups_taskCorr <- groups_taskCorr[-1]
}
filename <- "Sigma0.0-Epsilon0.0003-Bias1.1"
SocialNetwork = g_adj
ThresholdMatrix = threshMat
X_sub_g = X_g
epsilon = epsilon
# Calculate "sum" of task states/probs of neighbors
NeighborSums <- t(SocialNetwork) %*% X_sub_g
NeighborSums
g_adj
X_G
X_g
i = 5
activeInd <- NeighborSums[i, j]
activeInd
adjust <- epsilon * ((totalSums[i] - activeInd)  - activeInd)
totalSums <- rowSums(NeighborSums)
adjust <- epsilon * ((totalSums[i] - activeInd)  - activeInd)
adjust
