}
runMean <- cbind(runMean, replicate)
colnames(runMean) <- c(paste0("Task", 1:m), "replicate")
return(runMean)
})
runCorrs
runCorrs <- do.call("rbind", runCorrs)
View(runCorrs)
runCorrs <- as.data.frame(do.call("rbind", runCorrs))
# Bind task correlation data
# Calculate mean correlation for each n
runCorrs <- lapply(ens_taskCorr, function(x) {
# Unlist
runs <- do.call("rbind", x)
replicate <- runs[nrow(runs), ]
replicate <- unique(replicate)
runs <- runs[-nrow(runs), ]
# Calculate mean
runMean <- matrix(data = rep(NA, m), ncol =  m)
for (column in 1:m) {
runMean[ , column] <- mean(runs[ , column], na.rm = TRUE)
}
runMean <- cbind(runMean, replicate)
colnames(runMean) <- c(paste0("Task", 1:m), "replicate")
return(runMean)
})
runCorrs <- as.data.frame(do.call("rbind", runCorrs))
runCorrs$n <- n
runnCorrs$chunk <- chunk
View(runCorrs)
rm(list = ls())
source("scripts/util/__Util__MASTER.R")
library(RColorBrewer)
library(scales)
directory_path <- "output/Rdata/Sigma0-Epsilon0-Beta1.1_RankCorr/"
output_path <- "output/Rdata/_ProcessedData/"
run_info <- gsub("^.*(Sigma.*)/$", "\\1", directory_path, perl = TRUE)
####################
# Create folders
####################
# Get names of folders
folders <- list.files(directory_path)
output_folders <- list.files(output_path)
# Create folders for those not existing in processed data
missing_folders <- folders[!folders %in% output_folders]
missing_folders
folder = "RankCorr"
files <- list.files(paste0(directory_path, folder), full.names = TRUE)
files
for (file in files) {
load(file)
data <- do.call('rbind', data)
if (!exists("compiled_data")) {
compiled_data <- data
} else {
compiled_data <- rbind(compiled_data, data)
}
}
compiled_data <- as.data.frame(compiled_data)
View(compiled_data)
data[[1]]
data[1]
load(file)
data
data[1][1]
head(data[1])
test <- data[[1]]
rm(list = ls())
source("scripts/util/__Util__MASTER.R")
p <- 1 #prob of interact
runs <- c("Sigma0.05-Epsilon0-Beta1.1",
"Sigma0-Epsilon0.1-Beta1.1")
run_names <- c("Fixed", "Social")
interaction_rates <- lapply(1:length(runs), function(run) {
# Load social networks
files <- list.files(paste0("output/Rdata/_ProcessedData/Graphs/", runs[run], "/"), full.names = TRUE)
soc_networks <- list()
for (file in 1:length(files)) {
load(files[file])
soc_networks[[file]] <- listed_data
}
# Load threshold matrices
files <- list.files(paste0("output/Rdata/_ProcessedData/Thresh/", runs[run], "/"), full.names = TRUE)
thresh_data <- list()
for (file in 1:length(files)) {
load(files[file])
thresh_data[[file]] <- listed_data
}
# Loop through individual graphs
interaction_info <- lapply(1:length(soc_networks), function(i) {
# Get graphs
graphs <- soc_networks[[i]]
replicates <- length(graphs)
# For each each compute interaction matrix
# Get graph and make adjacency matrix
size_graph <- lapply(1:length(graphs), function(j) {
# Format: set diagonal, rescale, and make adj matrix
this_graph <- graphs[[j]]
diag(this_graph) <- NA
thresh <- as.data.frame(thresh_data[[i]][j])
thresh$ThreshRatio <- log(thresh$Thresh1 / thresh$Thresh2)
ratio <- order(thresh$ThreshRatio)
# Create order by threshold ratio
this_graph <- this_graph[ratio, ratio]
colnames(this_graph) <- 1:nrow(this_graph)
rownames(this_graph) <- colnames(this_graph)
g <- graph.adjacency(adjmatrix = this_graph, weighted = T)
edgelist_graph <- as.data.frame(get.edgelist(g))
names(edgelist_graph) <- c("From", "To")
edgelist_graph$Weight <- E(g)$weight
edgelist_graph$Interaction <- paste0(edgelist_graph$From, "-", edgelist_graph$To)
# return
return(edgelist_graph)
})
#Calculate baseline probability of interaction
dimensions <- dim(graphs[[1]])
not_chosen <- 1 - (( 1 / (dimensions[1] - 1)) * p)
expected_random <-  1 - not_chosen^2
# Bind
all_edgelist <- do.call("rbind", size_graph)
#  Calcualte 99% CI interval of interaction rate
edgelist_sig <- all_edgelist %>%
group_by(From, To, Interaction) %>%
# filter(!is.na(Weight)) %>%
summarise(samp_mean = mean(Weight),
samp_sd = sd(Weight),
samples = length(Weight)) %>%
mutate(error = qt(0.995,df = samples-1) * samp_sd/sqrt(samples),
CI_low = samp_mean - error,
CI_high = samp_mean + error) %>%
mutate(Lower_check = CI_low > expected_random,
Higher_check = CI_high > expected_random)
# Determine if it is different than random
edgelist_sig <- as.data.frame(edgelist_sig)
edgelist_sig$DiffDirection <- 0
edgelist_sig$DiffDirection[edgelist_sig$Lower_check & edgelist_sig$Higher_check] <- 1
edgelist_sig$DiffDirection[edgelist_sig$Lower_check==FALSE & edgelist_sig$Higher_check==FALSE] <- -1
# Make graph
edgelist_sig <- edgelist_sig %>%
summarise(Nonrandom = sum(DiffDirection!=0),
HigherThanRandom = sum(DiffDirection == 1),
LowerThanRandom = sum(DiffDirection == -1),
TotalInteractions = n()) %>%
mutate(PercentNonRandom = Nonrandom / TotalInteractions,
PercentHigher = HigherThanRandom / TotalInteractions,
PercentLower = LowerThanRandom / TotalInteractions,
n = dimensions[1],
Model = run_names[run])
# Return
print(paste0(run_names[run], ": ", dimensions[1]))
return(edgelist_sig)
})
# Bind and return
interaction_info <- do.call("rbind", interaction_info)
return(interaction_info)
})
# Bind
interaction_data <- do.call('rbind', interaction_rates)
# Graph
gg_interactions <- ggplot(interaction_data, aes(x = n, y = PercentNonRandom,
colour = Model, group = Model, fill = Model)) +
geom_line(size = 0.4, aes(linetype = Model)) +
geom_point(size = 0.8, shape = 21) +
scale_y_continuous(limits = c(0, 1)) +
scale_color_manual(name = "Threshold type",
values = c("#878787", "#4d4d4d")) +
scale_fill_manual(name = "Threshold type",
values = c("#ffffff", "#4d4d4d")) +
scale_linetype_manual(name = "Threshold type",
values = c("dotted", "solid")) +
xlab(expression(paste("Group Size (", italic(n), ")"))) +
ylab("% Non-random interactions") +
theme_ctokita() +
theme(aspect.ratio = 1,
legend.position = "none")
gg_interactions
# Graph
gg_interactions <- ggplot(interaction_data, aes(x = n, y = PercentNonRandom,
colour = Model, group = Model, fill = Model)) +
geom_line(size = 0.4, aes(linetype = Model)) +
geom_point(size = 0.8, shape = 21) +
scale_y_continuous(limits = c(0, 1)) +
scale_color_manual(name = "Threshold type",
values = c("#878787", "#4d4d4d")) +
scale_fill_manual(name = "Threshold type",
values = c("#ffffff", "#4d4d4d")) +
# scale_linetype_manual(name = "Threshold type",
#                       values = c("dotted", "solid")) +
xlab(expression(paste("Group Size (", italic(n), ")"))) +
ylab("% Non-random interactions") +
theme_ctokita() +
theme(aspect.ratio = 1,
legend.position = "none")
gg_interactions
# Graph
gg_interactions <- ggplot(interaction_data, aes(x = n, y = PercentNonRandom,
colour = Model, group = Model, fill = Model)) +
geom_line(size = 0.4, aes(linetype = Model)) +
geom_point(size = 0.8, shape = 21) +
scale_y_continuous(limits = c(0, 1)) +
scale_color_manual(name = "Threshold type",
values = c("#878787", "#4d4d4d")) +
scale_fill_manual(name = "Threshold type",
values = c("#ffffff", "#4d4d4d")) +
scale_linetype_manual(name = "Threshold type",
values = c("dashed", "solid")) +
xlab(expression(paste("Group Size (", italic(n), ")"))) +
ylab("% Non-random interactions") +
theme_ctokita() +
theme(aspect.ratio = 1,
legend.position = "none")
gg_interactions
ggsave(gg_interactions, filename = "Output/Networks/NetworkMetrics/PercentNonRandomInteractions.png",
height = 45, width = 45, units = "mm", dpi = 400)
# Graph
gg_interactions <- ggplot(interaction_data, aes(x = n, y = PercentNonRandom,
colour = Model, group = Model, fill = Model)) +
geom_line(size = 0.4) +
geom_point(size = 0.8, shape = 21) +
scale_y_continuous(limits = c(0, 1)) +
scale_color_manual(name = "Threshold type",
values = c("#878787", "#4d4d4d")) +
scale_fill_manual(name = "Threshold type",
values = c("#ffffff", "#4d4d4d")) +
xlab(expression(paste("Group Size (", italic(n), ")"))) +
ylab("% Non-random interactions") +
theme_ctokita() +
theme(aspect.ratio = 1,
legend.position = "none")
gg_interactions
ggsave(gg_interactions, filename = "Output/Networks/NetworkMetrics/PercentNonRandomInteractions.png",
height = 45, width = 45, units = "mm", dpi = 400)
ggsave(gg_interactions, filename = "Output/Networks/NetworkMetrics/PercentNonRandomInteractions.svg",
height = 45, width = 45, units = "mm")
source('~/Documents/Research/Tarnita Lab/Social Interaction DOL/SocialModel/scripts/2b_Process_ClusterSimData.R', echo=TRUE)
rm(list = ls())
source("scripts/util/__Util__MASTER.R")
library(RColorBrewer)
library(scales)
directory_path <- "output/Rdata/Sigma0-Epsilon0-Beta1.1_RankCorr/"
output_path <- "output/Rdata/_ProcessedData/"
run_info <- gsub("^.*(Sigma.*)/$", "\\1", directory_path, perl = TRUE)
####################
# Create folders
####################
# Get names of folders
folders <- list.files(directory_path)
output_folders <- list.files(output_path)
# Create folders for those not existing in processed data
missing_folders <- folders[!folders %in% output_folders]
missing_folders
####################
# Load data
####################
load("output/Rdata/_ProcessedData/Entropy/Sigma0-Epsilon0-Beta1.1_RankCorr.Rdata")
####################
# Load data
####################
load("output/Rdata/_ProcessedData/RankCorr/Sigma0-Epsilon0-Beta1.1_RankCorr.Rdata")
folder = "RankCorr"
################################################################################
#
# Comparing various specialization plots
#
################################################################################
rm(list = ls())
source("scripts/util/__Util__MASTER.R")
library(RColorBrewer)
library(scales)
directory_path <- "output/Rdata/Sigma0-Epsilon0-Beta1.1_RankCorr/"
output_path <- "output/Rdata/_ProcessedData/"
run_info <- gsub("^.*(Sigma.*)/$", "\\1", directory_path, perl = TRUE)
####################
# Create folders
####################
# Get names of folders
folders <- list.files(directory_path)
output_folders <- list.files(output_path)
# Create folders for those not existing in processed data
missing_folders <- folders[!folders %in% output_folders]
for (missing_folder in missing_folders) {
dir.create(paste0(output_path, missing_folder))
}
# Divide up folders into those where bound dataframes will be made
# and those where compiled lists will be made (for the sake of memory)
bind_folders <- folders[folders %in% c("Entropy", "TaskDist")]
list_folders <- folders[folders %in% c("Graphs", "Thresh", "Stim", "TaskTally", "Thresh1Time", "Thresh2Time")]
# Create subfolder to story data by group size
full_output_path <- paste0(output_path, folder, "/", run_info, "/")
folder = "RankCorr"
# Create subfolder to story data by group size
full_output_path <- paste0(output_path, folder, "/", run_info, "/")
# Get files
files <- list.files(paste0(directory_path, folder), full.names = TRUE)
# Get group sizes
group_sizes <- gsub(".*/([0-9]+)-[0-9]+.Rdata", "\\1", files, perl = TRUE)
group_sizes <- unique(group_sizes)
load(files[1])
View(data)
source('~/Documents/Research/Tarnita Lab/Social Interaction DOL/SocialModel/scripts/2b_Process_ClusterSimData.R', echo=TRUE)
####################
# Load data
####################
load("output/Rdata/_ProcessedData/RankCorr/Sigma0-Epsilon0-Beta1.1_RankCorr.Rdata")
View(compiled_data)
####################
# Load rank corr data and bind, save
####################
files <- list.files(paste0(directory_path, "RankCorr"), full.names = TRUE)
files
for (file in files) {
load(file)
if (!exists("compiled_data")) {
compiled_data <- data
} else {
compiled_data <- rbind(compiled_data, data)
}
}
rm(compiled_data)
####################
# Load rank corr data and bind, save
####################
files <- list.files(paste0(directory_path, "RankCorr"), full.names = TRUE)
for (file in files) {
load(file)
if (!exists("compiled_data")) {
compiled_data <- data
} else {
compiled_data <- rbind(compiled_data, data)
}
}
View(compiled_data)
qplot(compiled_data$n, compiled_data$Task1)
plot(compiled_data$n, compiled_data$Task1)
####################
# Load data
####################
load("output/Rdata/_ProcessedData/RankCorr/Sigma0-Epsilon0-Beta1.1_RankCorr.Rdata")
####################
# Process data
####################
rank_corr <- compiled_data %>%
mutate(Spec = (Task1 + Task 2) / 2)
####################
# Process data
####################
rank_corr <- compiled_data %>%
mutate(Spec = (Task1 + Task 2) / 2))
####################
# Process data
####################
rank_corr <- compiled_data %>%
mutate(Spec = (Task1 + Task2) / 2)
names(compiled_data)
####################
# Load data
####################
load("output/Rdata/_ProcessedData/RankCorr/Sigma0-Epsilon0-Beta1.1_RankCorr.Rdata")
View(compiled_data)
source('~/Documents/Research/Tarnita Lab/Social Interaction DOL/SocialModel/scripts/2b_Process_ClusterSimData.R', echo=TRUE)
rm(list = ls())
source("scripts/util/__Util__MASTER.R")
library(RColorBrewer)
library(scales)
####################
# Load data
####################
load("output/Rdata/_ProcessedData/RankCorr/Sigma0-Epsilon0-Beta1.1_RankCorr.Rdata")
####################
names(compiled_data)
#
# Comparing various specialization plots
#
################################################################################
rm(list = ls())
source("scripts/util/__Util__MASTER.R")
library(RColorBrewer)
library(scales)
directory_path <- "output/Rdata/Sigma0-Epsilon0-Beta1.1_RankCorr/"
output_path <- "output/Rdata/_ProcessedData/"
run_info <- gsub("^.*(Sigma.*)/$", "\\1", directory_path, perl = TRUE)
####################
####################
# Load rank corr data and bind, save
####################
files <- list.files(paste0(directory_path, "RankCorr"), full.names = TRUE)
for (file in files) {
load(file)
if (!exists("compiled_data")) {
compiled_data <- data
} else {
compiled_data <- rbind(compiled_data, data)
}
}
compiled_data <- as.data.frame(compiled_data)
source('~/Documents/Research/Tarnita Lab/Social Interaction DOL/SocialModel/scripts/2b_Process_ClusterSimData.R', echo=TRUE)
files <- list.files(paste0(directory_path, "RankCorr"), full.names = TRUE)
for (file in files) {
load(file)
if (!exists("compiled_data")) {
compiled_data <- data
} else {
compiled_data <- rbind(compiled_data, data)
}
}
compiled_data <- as.data.frame(compiled_data)
save(compiled_data, file = paste0(output_path, "RankCorr/", run_info, ".Rdata"))
rm(compiled_data)
rm(list = ls())
source("scripts/util/__Util__MASTER.R")
library(RColorBrewer)
library(scales)
####################
# Load data
####################
load("output/Rdata/_ProcessedData/RankCorr/Sigma0-Epsilon0-Beta1.1_RankCorr.Rdata")
####################
View(compiled_data)
####################
# Process data
####################
rank_corr <- compiled_data %>%
mutate(Spec = (Task1 + Task2) / 2)
View(rank_corr)
####################
# Process data
####################
rank_corr <- compiled_data %>%
mutate(Spec = (Task1 + Task2) / 2) %>%
group_by(n) %>%
summarise(MeanSpec = mean(Spec),
SESpec = sd(Spec)/sqrt(length(Spec)))
View(rank_corr)
####################
# Plot
####################
gg_spec <- ggplot(data = rank_corr, aes(x = n)) +
geom_line(aes(y = MeanSpec),
size = 0.4) +
geom_errorbar(aes(ymin = MeanSpec - SESpec, ymax = MeanSpec + SESESpec),
width = 0) +
geom_point(aes(y = MeanSpec),
size = 0.8) +
theme_classic() +
xlab(expression(paste("Group Size (", italic(n), ")"))) +
ylab(expression(paste("Specialization (rank corr.)"))) +
scale_x_continuous(breaks = seq(0, 100, 20)) +
theme(axis.text = element_text(colour = "black", size = 6),
axis.title = element_text(size = 7, face = "italic"),
legend.position = "none",
legend.title = element_text(size = 7,
face = "bold"),
legend.text = element_text(size = 6),
legend.key.height = unit(4, "mm"),
legend.key.width = unit(5, "mm"),
axis.ticks = element_line(size = 0.3, color = "black"),
axis.line = element_line(size = 0.3, color = "black"),
aspect.ratio = 1)
gg_spec
####################
# Plot
####################
gg_spec <- ggplot(data = rank_corr, aes(x = n)) +
geom_line(aes(y = MeanSpec),
size = 0.4) +
geom_errorbar(aes(ymin = MeanSpec - SESpec, ymax = MeanSpec + SESpec),
width = 0) +
geom_point(aes(y = MeanSpec),
size = 0.8) +
theme_classic() +
xlab(expression(paste("Group Size (", italic(n), ")"))) +
ylab(expression(paste("Specialization (rank corr.)"))) +
scale_x_continuous(breaks = seq(0, 100, 20)) +
theme(axis.text = element_text(colour = "black", size = 6),
axis.title = element_text(size = 7, face = "italic"),
legend.position = "none",
legend.title = element_text(size = 7,
face = "bold"),
legend.text = element_text(size = 6),
legend.key.height = unit(4, "mm"),
legend.key.width = unit(5, "mm"),
axis.ticks = element_line(size = 0.3, color = "black"),
axis.line = element_line(size = 0.3, color = "black"),
aspect.ratio = 1)
gg_spec
####################
# Plot
####################
gg_spec <- ggplot(data = rank_corr, aes(x = n)) +
geom_line(aes(y = MeanSpec),
size = 0.4) +
geom_errorbar(aes(ymin = MeanSpec - SESpec, ymax = MeanSpec + SESpec),
width = 0) +
geom_point(aes(y = MeanSpec),
size = 0.8) +
theme_classic() +
xlab(expression(paste("Group Size (", italic(n), ")"))) +
ylab(expression(paste("Specialization (rank corr.)"))) +
scale_x_continuous(breaks = seq(0, 100, 20)) +
scale_y_continuous(limits = c(0, 1)) +
theme(axis.text = element_text(colour = "black", size = 6),
axis.title = element_text(size = 7, face = "italic"),
legend.position = "none",
legend.title = element_text(size = 7,
face = "bold"),
legend.text = element_text(size = 6),
legend.key.height = unit(4, "mm"),
legend.key.width = unit(5, "mm"),
axis.ticks = element_line(size = 0.3, color = "black"),
axis.line = element_line(size = 0.3, color = "black"),
aspect.ratio = 1)
gg_spec
