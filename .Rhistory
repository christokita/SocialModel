# Loop through group size (and chucnks)
improveSpec <- sfLapply(1:nrow(run_in_parallel), function(k) {
# Set group size
n <- run_in_parallel[k, 1]
chunk <- run_in_parallel[k, 2]
# Prep lists for collection of simulation outputs from this group size
ens_thresh      <- list()
# Run Simulations
for (sim in 1:chunk_size) {
# Seed internal thresholds
threshMat <- seed_thresholds(n = n,
m = m,
threshold_means = ThreshM,
threshold_sds = ThreshSD)
ens_thresh[[sim]] <- threshMat
}
return(ens_thresh)
})
sfStop()
test <- lapply(improveSpec, function(i) {
bound <- do.call("rbind", i)
})
test <- do.call("rbind", test)
qplot(data = as.data.frame(test), x =Thresh1, y = Thresh2)
table(duplicated(test))
runs <- c("Sigma0.05-Epsilon0-Beta1.1",
"Sigma0-Epsilon0.1-Beta1.1")
run_names <- c("Fixed", "Social")
run = 2
print(runs[run])
files <- list.files(paste0("output/Rdata/_ProcessedData/Graphs/", runs[run], "/"), full.names = TRUE)
soc_networks <- list()
for (file in 1:length(files)) {
load(files[file])
soc_networks[[file]] <- listed_data
}
# Load threshold matrices
files <- list.files(paste0("output/Rdata/_ProcessedData/Thresh/", runs[run], "/"), full.names = TRUE)
thresh_data <- list()
for (file in 1:length(files)) {
load(files[file])
thresh_data[[file]] <- listed_data
}
i = 5
print(i * 5)
# Get graphs
graphs <- soc_networks[[i]]
replicates <- length(graphs)
j = 1
# Get graph and calculate threshold differences
this_graph <- graphs[[j]]
diag(this_graph) <- 0
thresh <- as.data.frame(thresh_data[[i]][j])
thresh$ThreshBias <- thresh$Thresh1 - thresh$Thresh2
this_graph
library(igraph)
g <- graph_from_adjacency_matrix(this_graph, weighted = T)
E(g)
E(g)$weight
# Calculate assortmnet
assort <- cluster_edge_betweenness(graph = g, weights = E(g)$weight, directed = F)
# Calculate assortmnet
clust <- cluster_edge_betweenness(graph = g, weights = E(g)$weight, directed = F)
clust
clust$edge.betweenness
# Calculate assortmnet
clust <- transitivity(graph = g, type = "global", weights = E(g)$weight)
clust
E(g)$weight
clust
network_clust <- lapply(1:length(runs), function(run) {
print(runs[run])
# Load social networks
files <- list.files(paste0("output/Rdata/_ProcessedData/Graphs/", runs[run], "/"), full.names = TRUE)
soc_networks <- list()
for (file in 1:length(files)) {
load(files[file])
soc_networks[[file]] <- listed_data
}
# Load threshold matrices
files <- list.files(paste0("output/Rdata/_ProcessedData/Thresh/", runs[run], "/"), full.names = TRUE)
thresh_data <- list()
for (file in 1:length(files)) {
load(files[file])
thresh_data[[file]] <- listed_data
}
# Loop through individual graphs
interaction_info <- lapply(1:length(soc_networks), function(i) {
print(i * 5)
# Get graphs
graphs <- soc_networks[[i]]
replicates <- length(graphs)
# For each each compute interaction matrix
# Get graph and make adjacency matrix
size_graph <- lapply(1:length(graphs), function(j) {
# Get graph and calculate threshold differences
this_graph <- graphs[[j]]
diag(this_graph) <- 0
thresh <- as.data.frame(thresh_data[[i]][j])
thresh$ThreshBias <- thresh$Thresh1 - thresh$Thresh2
g <- graph_from_adjacency_matrix(this_graph, weighted = T)
# Calculate clustering
clust <- transitivity(graph = g, type = "global", weights = E(g)$weight)
to_retun <- data.frame(n = nrow(this_graph), ClusterCoeff = clust)
# return
return(to_retun)
})
#Calculate baseline probability of interaction
size_graph <- do.call("rbind", size_graph)
})
# Bind and return
interaction_info <- do.call("rbind", interaction_info)
interaction_info$Model <- run_names[run]
return(interaction_info)
})
# Bind
clust_data <- do.call('rbind', network_clust)
clust_data <- clust_data %>%
group_by(Model, n) %>%
summarise(Clust_mean = mean(ClusterCoeff),
Clust_SD = sd(ClusterCoeff),
Clust_SE = sd(ClusterCoeff)/length(ClusterCoeff))
source("scripts/util/__Util__MASTER.R")
library(RColorBrewer)
library(scales)
clust_data <- clust_data %>%
group_by(Model, n) %>%
summarise(Clust_mean = mean(ClusterCoeff),
Clust_SD = sd(ClusterCoeff),
Clust_SE = sd(ClusterCoeff)/length(ClusterCoeff))
# Plot
gg_clust <- ggplot(data = assort_data, aes(x = n, y = Assort_mean,
colour = Model, group = Model, fill = Model)) +
geom_line(size = 0.4) +
geom_errorbar(aes(ymin = Clust_mean - Clust_SD, ymax = Clust_mean + Clust_SD),
width = 0,
size = 0.3) +
geom_point(size = 0.8, shape = 21) +
scale_color_manual(name = "Threshold",
values = c("#878787", "#4d4d4d")) +
scale_fill_manual(name = "Threshold",
values = c("#ffffff", "#4d4d4d")) +
scale_linetype_manual(name = "Threshold",
values = c("dotted", "solid")) +
scale_x_continuous(breaks = c(5, seq(20, 100, 20))) +
scale_y_continuous(breaks = seq(-0.25, 0.05, 0.05), limits = c(-0.26, 0.05)) +
xlab(expression(paste("Group Size (", italic(n), ")"))) +
ylab("Assortativity") +
theme_ctokita() +
theme(aspect.ratio = 1,
legend.position = "none",
legend.key.height = unit(0.5, "line"))
# Plot
gg_clust <- ggplot(data = clust_data, aes(x = n, y = Clust_mean,
colour = Model, group = Model, fill = Model)) +
geom_line(size = 0.4) +
geom_errorbar(aes(ymin = Clust_mean - Clust_SD, ymax = Clust_mean + Clust_SD),
width = 0,
size = 0.3) +
geom_point(size = 0.8, shape = 21) +
scale_color_manual(name = "Threshold",
values = c("#878787", "#4d4d4d")) +
scale_fill_manual(name = "Threshold",
values = c("#ffffff", "#4d4d4d")) +
scale_linetype_manual(name = "Threshold",
values = c("dotted", "solid")) +
scale_x_continuous(breaks = c(5, seq(20, 100, 20))) +
scale_y_continuous(breaks = seq(-0.25, 0.05, 0.05), limits = c(-0.26, 0.05)) +
xlab(expression(paste("Group Size (", italic(n), ")"))) +
ylab("Assortativity") +
theme_ctokita() +
theme(aspect.ratio = 1,
legend.position = "none",
legend.key.height = unit(0.5, "line"))
gg_clust
# Plot
gg_clust <- ggplot(data = clust_data, aes(x = n, y = Clust_mean,
colour = Model, group = Model, fill = Model)) +
geom_line(size = 0.4) +
geom_errorbar(aes(ymin = Clust_mean - Clust_SD, ymax = Clust_mean + Clust_SD),
width = 0,
size = 0.3) +
geom_point(size = 0.8, shape = 21) +
scale_color_manual(name = "Threshold",
values = c("#878787", "#4d4d4d")) +
scale_fill_manual(name = "Threshold",
values = c("#ffffff", "#4d4d4d")) +
scale_linetype_manual(name = "Threshold",
values = c("dotted", "solid")) +
scale_x_continuous(breaks = c(5, seq(20, 100, 20))) +
# scale_y_continuous(breaks = seq(-0.25, 0.05, 0.05), limits = c(-0.26, 0.05)) +
xlab(expression(paste("Group Size (", italic(n), ")"))) +
ylab("Assortativity") +
theme_ctokita() +
theme(aspect.ratio = 1,
legend.position = "none",
legend.key.height = unit(0.5, "line"))
gg_clust
View(clust_data)
network_clust <- lapply(1:length(runs), function(run) {
print(runs[run])
# Load social networks
files <- list.files(paste0("output/Rdata/_ProcessedData/Graphs/", runs[run], "/"), full.names = TRUE)
soc_networks <- list()
for (file in 1:length(files)) {
load(files[file])
soc_networks[[file]] <- listed_data
}
# Load threshold matrices
files <- list.files(paste0("output/Rdata/_ProcessedData/Thresh/", runs[run], "/"), full.names = TRUE)
thresh_data <- list()
for (file in 1:length(files)) {
load(files[file])
thresh_data[[file]] <- listed_data
}
# Loop through individual graphs
interaction_info <- lapply(1:length(soc_networks), function(i) {
print(i * 5)
# Get graphs
graphs <- soc_networks[[i]]
replicates <- length(graphs)
# For each each compute interaction matrix
# Get graph and make adjacency matrix
size_graph <- lapply(1:length(graphs), function(j) {
# Get graph and calculate threshold differences
this_graph <- graphs[[j]]
diag(this_graph) <- 0
thresh <- as.data.frame(thresh_data[[i]][j])
thresh$ThreshBias <- thresh$Thresh1 - thresh$Thresh2
g <- graph_from_adjacency_matrix(this_graph, weighted = T)
# Calculate clustering
clust <- transitivity(graph = g, type = "weighted", weights = E(g)$weight)
to_retun <- data.frame(n = nrow(this_graph), ClusterCoeff = clust)
# return
return(to_retun)
})
#Calculate baseline probability of interaction
size_graph <- do.call("rbind", size_graph)
})
# Bind and return
interaction_info <- do.call("rbind", interaction_info)
interaction_info$Model <- run_names[run]
return(interaction_info)
})
# Bind
clust_data <- do.call('rbind', network_clust)
clust_data <- clust_data %>%
group_by(Model, n) %>%
summarise(Clust_mean = mean(ClusterCoeff),
Clust_SD = sd(ClusterCoeff),
Clust_SE = sd(ClusterCoeff)/length(ClusterCoeff))
# Plot
gg_clust <- ggplot(data = clust_data, aes(x = n, y = Clust_mean,
colour = Model, group = Model, fill = Model)) +
geom_line(size = 0.4) +
geom_errorbar(aes(ymin = Clust_mean - Clust_SD, ymax = Clust_mean + Clust_SD),
width = 0,
size = 0.3) +
geom_point(size = 0.8, shape = 21) +
scale_color_manual(name = "Threshold",
values = c("#878787", "#4d4d4d")) +
scale_fill_manual(name = "Threshold",
values = c("#ffffff", "#4d4d4d")) +
scale_linetype_manual(name = "Threshold",
values = c("dotted", "solid")) +
scale_x_continuous(breaks = c(5, seq(20, 100, 20))) +
# scale_y_continuous(breaks = seq(-0.25, 0.05, 0.05), limits = c(-0.26, 0.05)) +
xlab(expression(paste("Group Size (", italic(n), ")"))) +
ylab("Assortativity") +
theme_ctokita() +
theme(aspect.ratio = 1,
legend.position = "none",
legend.key.height = unit(0.5, "line"))
gg_clust
# Get graph and calculate threshold differences
this_graph <- graphs[[j]]
this_graph
# Get graph and calculate threshold differences
this_graph <- graphs[[j]]
diag(this_graph) <- NA
mean(this_graph, na.rm = T)
#Calculate baseline probability of interaction
dimensions <- dim(this_graph)
not_chosen <- 1 - (( 1 / (dimensions[1] - 1)) * p)
not_chosen <- 1 - (( 1 / (dimensions[1] - 1)))
expected_random <-  1 - not_chosen^2
# make all interactions above random = 1
this_graph[this_graph > expected_random] <- 1
this_graph[this_graph <= expected_random] <- 0
this_graph
g <- graph_from_adjacency_matrix(this_graph)
# Calculate clustering
clust <- transitivity(graph = g, type = "global")
clust
network_clust <- lapply(1:length(runs), function(run) {
print(runs[run])
# Load social networks
files <- list.files(paste0("output/Rdata/_ProcessedData/Graphs/", runs[run], "/"), full.names = TRUE)
soc_networks <- list()
for (file in 1:length(files)) {
load(files[file])
soc_networks[[file]] <- listed_data
}
# Load threshold matrices
files <- list.files(paste0("output/Rdata/_ProcessedData/Thresh/", runs[run], "/"), full.names = TRUE)
thresh_data <- list()
for (file in 1:length(files)) {
load(files[file])
thresh_data[[file]] <- listed_data
}
# Loop through individual graphs
interaction_info <- lapply(1:length(soc_networks), function(i) {
print(i * 5)
# Get graphs
graphs <- soc_networks[[i]]
replicates <- length(graphs)
# For each each compute interaction matrix
# Get graph and make adjacency matrix
size_graph <- lapply(1:length(graphs), function(j) {
# Get graph and calculate baseline probability of interaction
this_graph <- graphs[[j]]
diag(this_graph) <- NA
#Calculate baseline probability of interaction
dimensions <- dim(this_graph)
not_chosen <- 1 - (( 1 / (dimensions[1] - 1)))
expected_random <-  1 - not_chosen^2
# make all interactions above random = 1
this_graph[this_graph > expected_random] <- 1
this_graph[this_graph <= expected_random] <- 0
g <- graph_from_adjacency_matrix(this_graph)
# Calculate clustering
clust <- transitivity(graph = g, type = "global")
to_retun <- data.frame(n = nrow(this_graph), ClusterCoeff = clust)
# return
return(to_retun)
})
#Calculate baseline probability of interaction
size_graph <- do.call("rbind", size_graph)
})
# Bind and return
interaction_info <- do.call("rbind", interaction_info)
interaction_info$Model <- run_names[run]
return(interaction_info)
})
# Bind
clust_data <- do.call('rbind', network_clust)
clust_data <- clust_data %>%
group_by(Model, n) %>%
summarise(Clust_mean = mean(ClusterCoeff),
Clust_SD = sd(ClusterCoeff),
Clust_SE = sd(ClusterCoeff)/length(ClusterCoeff))
# Plot
gg_clust <- ggplot(data = clust_data, aes(x = n, y = Clust_mean,
colour = Model, group = Model, fill = Model)) +
geom_line(size = 0.4) +
geom_errorbar(aes(ymin = Clust_mean - Clust_SD, ymax = Clust_mean + Clust_SD),
width = 0,
size = 0.3) +
geom_point(size = 0.8, shape = 21) +
scale_color_manual(name = "Threshold",
values = c("#878787", "#4d4d4d")) +
scale_fill_manual(name = "Threshold",
values = c("#ffffff", "#4d4d4d")) +
scale_linetype_manual(name = "Threshold",
values = c("dotted", "solid")) +
scale_x_continuous(breaks = c(5, seq(20, 100, 20))) +
# scale_y_continuous(breaks = seq(-0.25, 0.05, 0.05), limits = c(-0.26, 0.05)) +
xlab(expression(paste("Group Size (", italic(n), ")"))) +
ylab("Assortativity") +
theme_ctokita() +
theme(aspect.ratio = 1,
legend.position = "none",
legend.key.height = unit(0.5, "line"))
gg_clust
# Plot
gg_clust <- ggplot(data = clust_data, aes(x = n, y = Clust_mean,
colour = Model, group = Model, fill = Model)) +
geom_line(size = 0.4) +
geom_errorbar(aes(ymin = Clust_mean - Clust_SD, ymax = Clust_mean + Clust_SD),
width = 0,
size = 0.3) +
geom_point(size = 0.8, shape = 21) +
scale_color_manual(name = "Threshold",
values = c("#878787", "#4d4d4d")) +
scale_fill_manual(name = "Threshold",
values = c("#ffffff", "#4d4d4d")) +
scale_linetype_manual(name = "Threshold",
values = c("dotted", "solid")) +
scale_x_continuous(breaks = c(5, seq(20, 100, 20))) +
# scale_y_continuous(breaks = seq(-0.25, 0.05, 0.05), limits = c(-0.26, 0.05)) +
xlab(expression(paste("Group Size (", italic(n), ")"))) +
ylab("Clustering Coeff.") +
theme_ctokita() +
theme(aspect.ratio = 1,
legend.position = "none",
legend.key.height = unit(0.5, "line"))
gg_clust
install.packages("tnet")
library(tnet)
?clustering_w
library(tnet)
j
# Get graph and calculate baseline probability of interaction
this_graph <- graphs[[j]]
diag(this_graph) <- NA
# using Opsahl 2009 method
g <- graph_from_adjacency_matrix(this_graph, weighted = T)
e_list <- get.edgelist(g)
e_list$weight <- E(g)$weight
View(e_list)
e_list <- as.data.frame(get.edgelist(g))
e_list$weight <- E(g)$weight
clust <- clustering_w(e_list)
View(e_list)
# Get graph and calculate baseline probability of interaction
this_graph <- graphs[[j]]
diag(this_graph) <- 0
# using Opsahl 2009 method
g <- graph_from_adjacency_matrix(this_graph, weighted = T)
e_list <- as.data.frame(get.edgelist(g))
e_list$weight <- E(g)$weight
clust <- clustering_w(e_list)
clust
str(e_list)
e_list$V1 <- as.character(e_list$V1)
e_list$V2 <- as.character(e_list$V2)
str(e_list)
# using Opsahl 2009 method
g <- graph_from_adjacency_matrix(this_graph, weighted = T)
e_list <- as.data.frame(get.edgelist(g))
e_list <- e_list %>%
mutate(V1 = as.character(V1),
V2 = as.character(V2)) %>%
mutate(V1 = as.numeric(gsub("v-", "", V1)),
V2 = as.numeric(gsub("v-", "", V2)))
e_list$weight <- E(g)$weight
clust <- clustering_w(e_list)
clust
e_list
str(e_list)
# using Opsahl 2009 method
g <- graph_from_adjacency_matrix(this_graph, weighted = T)
e_list <- as.data.frame(get.edgelist(g))
e_list <- e_list %>%
mutate(V1 = as.character(V1),
V2 = as.character(V2)) %>%
mutate(V1 = gsub("v-", "", V1),
V2 = gsub("v-", "", V2))
e_list$weight <- E(g)$weight
clust <- clustering_w(e_list)
str(e_list)
network_clust <- lapply(1:length(runs), function(run) {
print(runs[run])
# Load social networks
files <- list.files(paste0("output/Rdata/_ProcessedData/Graphs/", runs[run], "/"), full.names = TRUE)
soc_networks <- list()
for (file in 1:length(files)) {
load(files[file])
soc_networks[[file]] <- listed_data
}
# Load threshold matrices
files <- list.files(paste0("output/Rdata/_ProcessedData/Thresh/", runs[run], "/"), full.names = TRUE)
thresh_data <- list()
for (file in 1:length(files)) {
load(files[file])
thresh_data[[file]] <- listed_data
}
# Loop through individual graphs
interaction_info <- lapply(1:length(soc_networks), function(i) {
print(i * 5)
# Get graphs
graphs <- soc_networks[[i]]
replicates <- length(graphs)
# For each each compute interaction matrix
# Get graph and make adjacency matrix
size_graph <- lapply(1:length(graphs), function(j) {
# Get graph and calculate baseline probability of interaction
this_graph <- graphs[[j]]
diag(this_graph) <- 0
#Calculate baseline probability of interaction
# dimensions <- dim(this_graph)
# not_chosen <- 1 - (( 1 / (dimensions[1] - 1)))
# expected_random <-  1 - not_chosen^2
# # make all interactions above random = 1
# this_graph[this_graph > expected_random] <- 1
# this_graph[this_graph <= expected_random] <- 0
# g <- graph_from_adjacency_matrix(this_graph)
# # Calculate clustering
# clust <- transitivity(graph = g, type = "global")
# to_return <- data.frame(n = nrow(this_graph), ClusterCoeff = clust)
# using Opsahl 2009 method
g <- graph_from_adjacency_matrix(this_graph, weighted = T)
e_list <- as.data.frame(get.edgelist(g))
e_list <- e_list %>%
mutate(V1 = as.character(V1),
V2 = as.character(V2)) %>%
mutate(V1 = as.numeric(gsub("v-", "", V1)),
V2 = as.numeric(gsub("v-", "", V2)))
e_list$weight <- E(g)$weight
clust <- clustering_w(e_list)
to_return <- data.frame(n = nrow(this_graph), ClusterCoeff = clust)
# return
return(to_return)
})
#Calculate baseline probability of interaction
size_graph <- do.call("rbind", size_graph)
})
# Bind and return
interaction_info <- do.call("rbind", interaction_info)
interaction_info$Model <- run_names[run]
return(interaction_info)
})
