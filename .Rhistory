}
return(ens_thresh)
})
sfStop()
test <- lapply(improveSpec, function(i) {
bound <- do.call("rbind", i)
})
test <- do.call("rbind", test)
qplot(data = as.data.frame(test), x =Thresh1, y = Thresh2)
rm(list = ls())
setwd('.')
####################
# Install missing packages before everything
####################
source("scripts/util/__Util_MiscFunctions.R")
needed_packages <- c("reshape2", "igraph", "ggplot2", "msm", "dplyr", "tidyr", "gtools", "parallel", "snowfall")
install_missing_packages(needed_packages)
####################
# Source necessary scripts/libraries
####################
source("scripts/util/__Util__MASTER.R")
library(parallel)
library(snowfall)
####################
# Set global variables
####################
# Initial paramters: Free to change
# Base parameters
Ns             <- c(5, 10) #vector of number of individuals to simulate
m              <- 2 #number of tasks
gens           <- 10000 #number of generations to run simulation
reps           <- 20 #number of replications per simulation (for ensemble)
chunk_size     <- 5 #number of simulations sent to single core
# Threshold Parameters
ThreshM        <- rep(10, m) #population threshold means
ThreshSD       <- ThreshM * 0.1 #population threshold standard deviations
InitialStim    <- rep(0, m) #intital vector of stimuli
deltas         <- rep(0.6, m) #vector of stimuli increase rates
alpha          <- m #efficiency of task performance
quitP          <- 0.2 #probability of quitting task once active
# Social Network Parameters
p              <- 0.5 #baseline probablity of initiating an interaction per time step
epsilon        <- 0.01 #relative weighting of social interactions for adjusting thresholds
beta           <- 1.1 #probability of interacting with individual in same state relative to others
####################
# Prep for Parallelization
####################
# Break up parameter replications into smaller batches
chunk_run  <- 1:(reps / chunk_size)
run_in_parallel <- expand.grid(n = Ns, run = chunk_run)
run_in_parallel <- run_in_parallel %>%
arrange(n)
# Prepare for parallel
no_cores <- detectCores() - 1
sfInit(parallel = TRUE, cpus = no_cores)
sfExportAll()
sfLibrary(dplyr)
sfLibrary(reshape2)
sfLibrary(igraph)
sfLibrary(ggplot2)
sfLibrary(msm)
sfLibrary(gtools)
sfLibrary(snowfall)
sfClusterSetupRNGstream(seed = 323)
####################
# Run ensemble simulation
####################
# Loop through group size (and chucnks)
improveSpec <- sfLapply(1:nrow(run_in_parallel), function(k) {
# Set group size
n <- run_in_parallel[k, 1]
chunk <- run_in_parallel[k, 2]
# Prep lists for collection of simulation outputs from this group size
ens_thresh      <- list()
# Run Simulations
for (sim in 1:chunk_size) {
# Seed internal thresholds
threshMat <- seed_thresholds(n = n,
m = m,
threshold_means = ThreshM,
threshold_sds = ThreshSD)
ens_thresh[[sim]] <- threshMat
}
return(ens_thresh)
})
sfStop()
test <- lapply(improveSpec, function(i) {
bound <- do.call("rbind", i)
})
test <- do.call("rbind", test)
qplot(data = as.data.frame(test), x =Thresh1, y = Thresh2)
rm(list = ls())
setwd('.')
####################
# Install missing packages before everything
####################
source("scripts/util/__Util_MiscFunctions.R")
needed_packages <- c("reshape2", "igraph", "ggplot2", "msm", "dplyr", "tidyr", "gtools", "parallel", "snowfall")
install_missing_packages(needed_packages)
####################
# Source necessary scripts/libraries
####################
source("scripts/util/__Util__MASTER.R")
library(parallel)
library(snowfall)
####################
# Set global variables
####################
# Initial paramters: Free to change
# Base parameters
Ns             <- c(5, 10, 20) #vector of number of individuals to simulate
m              <- 2 #number of tasks
gens           <- 10000 #number of generations to run simulation
reps           <- 20 #number of replications per simulation (for ensemble)
chunk_size     <- 5 #number of simulations sent to single core
# Threshold Parameters
ThreshM        <- rep(10, m) #population threshold means
ThreshSD       <- ThreshM * 0.1 #population threshold standard deviations
InitialStim    <- rep(0, m) #intital vector of stimuli
deltas         <- rep(0.6, m) #vector of stimuli increase rates
alpha          <- m #efficiency of task performance
quitP          <- 0.2 #probability of quitting task once active
# Social Network Parameters
p              <- 0.5 #baseline probablity of initiating an interaction per time step
epsilon        <- 0.01 #relative weighting of social interactions for adjusting thresholds
beta           <- 1.1 #probability of interacting with individual in same state relative to others
####################
# Prep for Parallelization
####################
# Break up parameter replications into smaller batches
chunk_run  <- 1:(reps / chunk_size)
run_in_parallel <- expand.grid(n = Ns, run = chunk_run)
run_in_parallel <- run_in_parallel %>%
arrange(n)
# Prepare for parallel
no_cores <- detectCores() - 1
sfInit(parallel = TRUE, cpus = no_cores)
sfExportAll()
sfLibrary(dplyr)
sfLibrary(reshape2)
sfLibrary(igraph)
sfLibrary(ggplot2)
sfLibrary(msm)
sfLibrary(gtools)
sfLibrary(snowfall)
sfClusterSetupRNGstream(seed = 323)
####################
# Run ensemble simulation
####################
# Loop through group size (and chucnks)
improveSpec <- sfLapply(1:nrow(run_in_parallel), function(k) {
# Set group size
n <- run_in_parallel[k, 1]
chunk <- run_in_parallel[k, 2]
# Prep lists for collection of simulation outputs from this group size
ens_thresh      <- list()
# Run Simulations
for (sim in 1:chunk_size) {
# Seed internal thresholds
threshMat <- seed_thresholds(n = n,
m = m,
threshold_means = ThreshM,
threshold_sds = ThreshSD)
ens_thresh[[sim]] <- threshMat
}
return(ens_thresh)
})
sfStop()
test <- lapply(improveSpec, function(i) {
bound <- do.call("rbind", i)
})
test <- do.call("rbind", test)
qplot(data = as.data.frame(test), x =Thresh1, y = Thresh2)
duplicated(test)
table(duplicated(test))
source('~/Documents/Research/Tarnita Lab/Social Interaction DOL/SocialModel/scripts/2_Cluster_SocialThreshModel.R', echo=TRUE)
source('~/Documents/Research/Tarnita Lab/Social Interaction DOL/SocialModel/scripts/2_Cluster_SocialThreshModel.R', echo=TRUE)
tag_parallel_runs <- function(matrix, n, simulation, chunk) {
matrix['n'] <- n
matrix['sim'] <- simulation
matrix['chunk'] <- chunk
return(matrix)
}
source('~/Documents/Research/Tarnita Lab/Social Interaction DOL/SocialModel/scripts/2_Cluster_SocialThreshModel.R', echo=TRUE)
source('~/Documents/Research/Tarnita Lab/Social Interaction DOL/SocialModel/scripts/2_Cluster_SocialThreshModel.R', echo=TRUE)
?transform
?gather
source('~/Documents/Research/Tarnita Lab/Social Interaction DOL/SocialModel/scripts/2_Cluster_SocialThreshModel.R', echo=TRUE)
improveSpec[1]
names(improveSpec[1])
names(improveSpec[[1]])
names(improveSpec[[2]])
improveSpec[[1]][[1]]
improveSpec[[2]][[1]]
improveSpec[[1]][[2]]
improveSpec[[1]][[1]][1]
n <- run_in_parallel[k, 1]
chunk <- run_in_parallel[k, 2]
# Prep lists for collection of simulation outputs from this group size
ens_taskDist    <- list()
ens_taskTally   <- list()
ens_entropy     <- list()
ens_stim        <- list()
ens_thresh      <- list()
ens_thresh1Time <- list()
ens_thresh2Time <- list()
ens_graphs      <- list()
k = 1
n <- run_in_parallel[k, 1]
chunk <- run_in_parallel[k, 2]
# Prep lists for collection of simulation outputs from this group size
ens_taskDist    <- list()
ens_taskTally   <- list()
ens_entropy     <- list()
ens_stim        <- list()
ens_thresh      <- list()
ens_thresh1Time <- list()
ens_thresh2Time <- list()
ens_graphs      <- list()
for (sim in 1:chunk_size) {
####################
# Seed structures and intial matrices
####################
# Set initial probability matrix (P_g)
P_g <- matrix(data = rep(0, n * m), ncol = m)
# Seed task (external) stimuli
stimMat <- seed_stimuls(intitial_stim = InitialStim,
gens = gens)
# Seed internal thresholds
threshMat <- seed_thresholds(n = n,
m = m,
threshold_means = ThreshM,
threshold_sds = ThreshSD)
# Start task performance
X_g <- matrix(data = rep(0, length(P_g)), ncol = ncol(P_g))
# Create cumulative task performance matrix
X_tot <- X_g
# Create cumulative adjacency matrix
g_tot <-  matrix(data = rep(0, n * n), ncol = n)
colnames(g_tot) <- paste0("v-", 1:n)
rownames(g_tot) <- paste0("v-", 1:n)
# Prep lists for data collection within simulation
taskTally <- list()
thresh1time <- list()
thresh2time <- list()
thresh1time[[1]] <- threshMat[ ,1]
thresh2time[[1]] <- threshMat[ ,2]
####################
# Simulate individual run
####################
# Run simulation
for (t in 1:gens) {
# Current timestep is actually t+1 in this formulation, because first row is timestep 0
# Update stimuli
stimMat <- update_stim(stim_matrix = stimMat,
deltas = deltas,
alpha = alpha,
state_matrix = X_g,
time_step = t)
# Calculate task demand based on global stimuli
P_g <- calc_determ_thresh(time_step        = t + 1, # first row is generation 0
threshold_matrix = threshMat,
stimulus_matrix  = stimMat)
# Update task performance
X_g <- update_task_performance(task_probs   = P_g,
state_matrix = X_g,
quit_prob    = quitP)
# Update social network (previously this was before probability/task update)
g_adj <- temporalNetwork(X_sub_g = X_g,
prob_interact = p,
bias = beta)
g_tot <- g_tot + g_adj
# Adjust thresholds
threshMat <- adjust_thresholds_social_capped(social_network = g_adj,
threshold_matrix = threshMat,
state_matrix = X_g,
epsilon = epsilon,
threshold_max = 2 * ThreshM[1])
# Capture threshold values
thresh1time[[t + 1]] <- threshMat[,1]
thresh2time[[t + 1]] <- threshMat[,2]
# Update total task performance profile
X_tot <- X_tot + X_g
# Capture current task performance tally
tally <- matrix(c(t, colSums(X_g)), ncol = ncol(X_g) + 1)
colnames(tally) <- c("t", colnames(X_g))
taskTally[[t]] <- tally
}
####################
# Post run calculations
####################
# Bind together task tally
print(sim)
####################
# Seed structures and intial matrices
####################
# Set initial probability matrix (P_g)
P_g <- matrix(data = rep(0, n * m), ncol = m)
# Seed task (external) stimuli
stimMat <- seed_stimuls(intitial_stim = InitialStim,
gens = gens)
# Seed internal thresholds
threshMat <- seed_thresholds(n = n,
m = m,
threshold_means = ThreshM,
threshold_sds = ThreshSD)
# Start task performance
X_g <- matrix(data = rep(0, length(P_g)), ncol = ncol(P_g))
# Create cumulative task performance matrix
X_tot <- X_g
# Create cumulative adjacency matrix
g_tot <-  matrix(data = rep(0, n * n), ncol = n)
colnames(g_tot) <- paste0("v-", 1:n)
rownames(g_tot) <- paste0("v-", 1:n)
# Prep lists for data collection within simulation
taskTally <- list()
thresh1time <- list()
thresh2time <- list()
thresh1time[[1]] <- threshMat[ ,1]
thresh2time[[1]] <- threshMat[ ,2]
####################
# Simulate individual run
####################
# Run simulation
for (t in 1:gens) {
# Current timestep is actually t+1 in this formulation, because first row is timestep 0
# Update stimuli
stimMat <- update_stim(stim_matrix = stimMat,
deltas = deltas,
alpha = alpha,
state_matrix = X_g,
time_step = t)
# Calculate task demand based on global stimuli
P_g <- calc_determ_thresh(time_step        = t + 1, # first row is generation 0
threshold_matrix = threshMat,
stimulus_matrix  = stimMat)
# Update task performance
X_g <- update_task_performance(task_probs   = P_g,
state_matrix = X_g,
quit_prob    = quitP)
# Update social network (previously this was before probability/task update)
g_adj <- temporalNetwork(X_sub_g = X_g,
prob_interact = p,
bias = beta)
g_tot <- g_tot + g_adj
# Adjust thresholds
threshMat <- adjust_thresholds_social_capped(social_network = g_adj,
threshold_matrix = threshMat,
state_matrix = X_g,
epsilon = epsilon,
threshold_max = 2 * ThreshM[1])
# Capture threshold values
thresh1time[[t + 1]] <- threshMat[,1]
thresh2time[[t + 1]] <- threshMat[,2]
# Update total task performance profile
X_tot <- X_tot + X_g
# Capture current task performance tally
tally <- matrix(c(t, colSums(X_g)), ncol = ncol(X_g) + 1)
colnames(tally) <- c("t", colnames(X_g))
taskTally[[t]] <- tally
}
####################
# Post run calculations
####################
# Bind together task tally
col_names <- colnames(taskTally[[1]])
taskTally <- matrix(unlist(taskTally),
ncol = length(taskTally[[1]]),
byrow = TRUE,
dimnames = list(c(NULL), c(col_names)))
test <- label_parallel_runs(matrix = taskTally, n = n, simulation = sim, chunk = chunk)
sim = 1
test <- label_parallel_runs(matrix = taskTally, n = n, simulation = sim, chunk = chunk)
test
taskTally
test
# Calculate Entropy
entropy <- mutualEntropy(TotalStateMat = X_tot)
entropy
entropy <- label_parallel_runs(matrix = entropy, n = n, simulation = sim, chunk = chunk)
entropy
nrow(taskTally)
names(taskTally)
colnames(taskTally)
matrix <- taskTally
matrix <- c(matrix, rep(n, rows))
rows <- nrow(matrix)
col_names <- colnames(taskTally)
matrix <- c(matrix, rep(n, rows))
matrix
head(matrix)
matrix <- taskTally
matrix <- cbind(matrix, rep(n, rows))
matrix
class(matrix)
####################
# Tag runs for parallel computing
####################
label_parallel_runs <- function(matrix, n, simulation, chunk) {
rows <- nrow(matrix)
col_names <- colnames(matrix)
matrix <- cbind(matrix, rep(n, rows))
matrix <- cbind(matrix, rep(simulation, rows))
matrix <- cbind(matrix, rep(chunk, rows))
colnames(matrix) <- c(col_names, 'n', 'sim', 'chunk')
return(matrix)
}
# Calculate Entropy
entropy <- mutualEntropy(TotalStateMat = X_tot)
entropy <- label_parallel_runs(matrix = entropy, n = n, simulation = sim, chunk = chunk)
entropy
# Calculate total task distribution
totalTaskDist <- X_tot / gens
totalTaskDist <- label_parallel_runs(matrix = totalTaskDist, n = n, simulation = sim, chunk = chunk)
totalTaskDist
source('~/Documents/Research/Tarnita Lab/Social Interaction DOL/SocialModel/scripts/2_Cluster_SocialThreshModel.R', echo=TRUE)
improveSpec[[1]][[1]]
improveSpec[[1]][[2]]
improveSpec[[3]][[2]]
improveSpec[[3]][[3]]
sigma
ThreshSD
ThreshSD[1]
####################
# Save data
####################
filename <- paste0("Sigma", ThreshSD[1], "-Epsilon", epsilon, "-Beta", beta, ".R")
filename
ThreshSD       <- ThreshM * 0.0 #population threshold standard deviations
####################
# Save data
####################
filename <- paste0("Sigma", ThreshSD[1], "-Epsilon", epsilon, "-Beta", beta, ".R")
filename
filename <- gsub(filename, "\.", "")
filename <- gsub(filename, "\\.", "")
filename
####################
# Save data
####################
filename <- paste0("Sigma", ThreshSD[1], "-Epsilon", epsilon, "-Beta", beta)
filename <- gsub(filename, pattern = "\\.", replacement = "")
####################
# Save data
####################
filename <- paste0("Sigma", ThreshSD[1], "-Epsilon", epsilon, "-Beta", beta)
####################
# Save data
####################
filename <- paste0("Sigma", ThreshSD[1], "-Epsilon", epsilon, "-Beta", beta, ".R")
####################
# Save data
####################
filename <- paste0("/output/Sigma", ThreshSD[1], "-Epsilon", epsilon, "-Beta", beta, ".R")
filename
save(parallel_simulations, file = filename)
save(improveSpec, file = filename)
?save
####################
# Save data
####################
filename <- paste0("/output/Sigma", ThreshSD[1], "-Epsilon", epsilon, "-Beta", beta, ".Rdata")
save(improveSpec, file = filename)
####################
# Save data
####################
filename <- paste0("/output/RData/Sigma", ThreshSD[1], "-Epsilon", epsilon, "-Beta", beta, ".Rdata")
save(improveSpec, file = filename)
filename
####################
# Save data
####################
filename <- paste0("/output/Rdata/Sigma", ThreshSD[1], "-Epsilon", epsilon, "-Beta", beta, ".Rdata")
save(improveSpec, file = filename)
filename <- gsub(filename, "\\.", "_")
####################
# Save data
####################
filename <- paste0("/output/Rdata/Sigma", ThreshSD[1], "-Epsilon", epsilon, "-Beta", beta, ".Rdata")
filename <- gsub(filename, pattern = "\\.",replacement =  "_")
save(improveSpec, file = filename)
getwd()
####################
# Save data
####################
filename <- paste0("output/Rdata/Sigma", ThreshSD[1], "-Epsilon", epsilon, "-Beta", beta, ".Rdata")
save(improveSpec, file = filename)
####################
# Save data
####################
filename <- paste0(ThreshSD[1], "-Epsilon", epsilon, "-Beta", beta, ".Rdata")
filename <- gsub(filename, pattern = "\\.",replacement =  "_")
save(improveSpec, file = filename)
####################
# Save data
####################
filename <- paste0(ThreshSD[1], "-Epsilon", epsilon, "-Beta", beta, ".Rdata")
save(improveSpec, file = filename)
####################
# Save data
####################
filename <- paste0("Sigma", ThreshSD[1], "-Epsilon", epsilon, "-Beta", beta, ".Rdata")
filename
version
require(installR)
require(installr)
install.packages("installr")
version
source('~/Documents/Research/Tarnita Lab/Social Interaction DOL/SocialModel/scripts/2_Cluster_SocialThreshModel.R', echo=TRUE)
source('~/Documents/Research/Tarnita Lab/Social Interaction DOL/SocialModel/scripts/2_Cluster_SocialThreshModel.R', echo=TRUE)
source('~/Documents/Research/Tarnita Lab/Social Interaction DOL/SocialModel/scripts/2_Cluster_SocialThreshModel.R', echo=TRUE)
source('~/Documents/Research/Tarnita Lab/Social Interaction DOL/SocialModel/scripts/2_Cluster_SocialThreshModel.R', echo=TRUE)
