scale_fill_gradientn(colours = pal, name = "Behavioral\nspecialization",
limits = c(0, 1)) +
scale_colour_gradientn(colours = pal, name = "Behavioral\nspecialization",
limits = c(0, 1)) +
xlab(expression(paste("Interaction Bias (", italic(beta), ")"))) +
ylab(expression(paste( "Social influence (", italic(epsilon), ")"))) +
theme(axis.text = element_text(colour = "black", size = 6),
axis.title = element_text(size = 7),
legend.title = element_text(size = 7),
legend.text = element_text(size = 6),
legend.key.height = unit(5, "mm"),
legend.key.width = unit(2, "mm"),
legend.position = "none",
axis.ticks = element_line(size = 0.3, color = "black"),
panel.border = element_rect(fill = NA, size = 0.3, color = "black"),
aspect.ratio = 1)
gg_betaeps
gg_betaeps
ggsave(gg_betaeps, "output/ParameterSpace/Plots/BeataEpsSweep_n60.png")
ggsave(gg_betaeps, "output/ParameterSpace/Plots/BeataEpsSweep_n60.png", height = 45, width = 45, units = "mm", dpi = 400)
ggsave(gg_betaeps, file = "output/ParameterSpace/Plots/BeataEpsSweep_n60.png", height = 45, width = 45, units = "mm", dpi = 400)
rm(list = ls())
source("scripts/util/__Util__MASTER.R")
p <- 1 #prob of interact
runs <- c("Sigma0.05-Epsilon0-Beta1.1",
"Sigma0-Epsilon0.1-Beta1.1")
run_names <- c("Fixed", "Social")
run = 2
files <- list.files(paste0("output/Rdata/_ProcessedData/Graphs/", runs[run], "/"), full.names = TRUE)
soc_networks <- list()
for (file in 1:length(files)) {
load(files[file])
soc_networks[[file]] <- listed_data
}
# Load threshold matrices
files <- list.files(paste0("output/Rdata/_ProcessedData/Thresh/", runs[run], "/"), full.names = TRUE)
thresh_data <- list()
for (file in 1:length(files)) {
load(files[file])
thresh_data[[file]] <- listed_data
}
runs
i = 20
graphs <- soc_networks[[i]]
replicates <- length(graphs)
j = 1
this_graph <- graphs[[j]]
diag(this_graph) <- 0
g <- graph_from_adjacency_matrix(this_graph, mode = "undirected", weighted = TRUE)
g_clust <- cluster_fast_greedy(g, weights = E(g)$weight)
g_clust
mod <- modularity(g_clust)
mod
# For each each compute interaction matrix
# Get graph and make adjacency matrix
size_graph <- lapply(1:length(graphs), function(j) {
# Format: set diagonal, rescale, and make adj matrix
this_graph <- graphs[[j]]
diag(this_graph) <- 0
g <- graph_from_adjacency_matrix(this_graph, mode = "undirected", weighted = TRUE)
g_clust <- cluster_fast_greedy(g, weights = E(g)$weight)
# g_membership <- membership(g_clust)
# mod <- modularity(g, membership = g_membership, weights = E(g)$weight)
mod <- modularity(g_clust)
clust_coeff <- transitivity(graph = g, type = "weighted", weights = E(g)$weight)
# return
replicate_row <- data.frame(n = nrow(this_graph),
Modularity = mod,
ClustCoeff =  mean(clust_coeff, na.rm = TRUE))
return(replicate_row)
})
size_data <- do.call("rbind", size_graph)
View(size_data)
i = 10
graphs <- soc_networks[[i]]
replicates <- length(graphs)
# For each each compute interaction matrix
# Get graph and make adjacency matrix
size_graph <- lapply(1:length(graphs), function(j) {
# Format: set diagonal, rescale, and make adj matrix
this_graph <- graphs[[j]]
diag(this_graph) <- 0
g <- graph_from_adjacency_matrix(this_graph, mode = "undirected", weighted = TRUE)
g_clust <- cluster_fast_greedy(g, weights = E(g)$weight)
# g_membership <- membership(g_clust)
# mod <- modularity(g, membership = g_membership, weights = E(g)$weight)
mod <- modularity(g_clust)
clust_coeff <- transitivity(graph = g, type = "weighted", weights = E(g)$weight)
# return
replicate_row <- data.frame(n = nrow(this_graph),
Modularity = mod,
ClustCoeff =  mean(clust_coeff, na.rm = TRUE))
return(replicate_row)
})
size_data <- do.call("rbind", size_graph)
View(size_graph)
View(size_data)
run = 1
files <- list.files(paste0("output/Rdata/_ProcessedData/Graphs/", runs[run], "/"), full.names = TRUE)
soc_networks <- list()
for (file in 1:length(files)) {
load(files[file])
soc_networks[[file]] <- listed_data
}
# Load threshold matrices
files <- list.files(paste0("output/Rdata/_ProcessedData/Thresh/", runs[run], "/"), full.names = TRUE)
thresh_data <- list()
for (file in 1:length(files)) {
load(files[file])
thresh_data[[file]] <- listed_data
}
i = 2
# Get graphs
graphs <- soc_networks[[i]]
replicates <- length(graphs)
# For each each compute interaction matrix
# Get graph and make adjacency matrix
size_graph <- lapply(1:length(graphs), function(j) {
# Format: set diagonal, rescale, and make adj matrix
this_graph <- graphs[[j]]
diag(this_graph) <- 0
g <- graph_from_adjacency_matrix(this_graph, mode = "undirected", weighted = TRUE)
g_clust <- cluster_fast_greedy(g, weights = E(g)$weight)
# g_membership <- membership(g_clust)
# mod <- modularity(g, membership = g_membership, weights = E(g)$weight)
mod <- modularity(g_clust)
clust_coeff <- transitivity(graph = g, type = "weighted", weights = E(g)$weight)
# return
replicate_row <- data.frame(n = nrow(this_graph),
Modularity = mod,
ClustCoeff =  mean(clust_coeff, na.rm = TRUE))
return(replicate_row)
})
size_data <- do.call("rbind", size_graph)
View(size_data)
hist(size_data$Modularity)
rm(list = ls())
source("scripts/util/__Util__MASTER.R")
library(RColorBrewer)
library(scales)
library(viridis)
library(ggridges)
run <- "Sigma0.05-Epsilon0-Beta1.1"
####################
# Load data
####################
load("output/Rdata/_ProcessedData/TaskDist/Sigma0-Epsilon0.1-Beta1.1.Rdata")
social_data <- compiled_data
social_data$Model <- "Social"
load("output/Rdata/_ProcessedData/TaskDist/Sigma0.05-Epsilon0-Beta1.1.Rdata")
fixed_data <- compiled_data
fixed_data$Model <- "Fixed"
behav_data <- rbind(social_data, fixed_data) %>%
mutate(Set = paste0(sim, chunk, collapse = "-"))
head(behav_data)
behav_data$Set[2]
behav_data <- rbind(social_data, fixed_data) %>%
mutate(Set = paste(sim, chunk, sep = "-"))
behav_data$Set[2]
rm(list = ls())
source("scripts/util/__Util__MASTER.R")
library(RColorBrewer)
library(scales)
library(viridis)
library(ggridges)
run <- "Sigma0.05-Epsilon0-Beta1.1"
####################
# Load data
####################
load("output/Rdata/_ProcessedData/TaskDist/Sigma0-Epsilon0.1-Beta1.1.Rdata")
social_data <- compiled_data
social_data$Model <- "Social"
load("output/Rdata/_ProcessedData/TaskDist/Sigma0.05-Epsilon0-Beta1.1.Rdata")
fixed_data <- compiled_data
fixed_data$Model <- "Fixed"
behav_data <- rbind(social_data, fixed_data) %>%
mutate(Set = paste(sim, chunk, sep = "-"))
rm(compiled_data, social_data, fixed_data)
####################
#  Look at raw behavioral distributions
####################
behav_analysis <- behav_data %>%
filter(n %in% c(10, 25, 50, 90),
Set == "1-1")
# Plot behavioral distributions
gg_behav_dist <- ggplot(data = behav_analysis, aes(x = Task1, y = Task2)) +
geom_point(size = 0.1) +
theme_ctokita() +
facet_grid(Model~n)
gg_behav_dist
####################
#  Look at raw behavioral distributions
####################
behav_analysis <- behav_data %>%
filter(n %in% c(10, 25, 50, 90),
Set == "2-1")
# Plot behavioral distributions
gg_behav_dist <- ggplot(data = behav_analysis, aes(x = Task1, y = Task2)) +
geom_point(size = 0.1) +
theme_ctokita() +
facet_grid(Model~n)
gg_behav_dist
behav_analysis <- behav_data %>%
filter(n %in% c(10, 25, 50, 90)
)
# Plot behavioral distributions
gg_behav_dist <- ggplot(data = behav_analysis, aes(x = Task1, y = Task2)) +
geom_point(size = 0.1) +
theme_ctokita() +
facet_grid(Model~n)
gg_behav_dist
# Plot behavioral distributions
gg_behav_dist <- ggplot(data = behav_analysis, aes(x = Task1, y = Task2)) +
geom_point(size = 0.1, alpha = 0.2) +
theme_ctokita() +
facet_grid(Model~n)
gg_behav_dist
# Plot behavioral distributions
gg_behav_dist <- ggplot(data = behav_analysis, aes(x = Task1, y = Task2)) +
geom_point(size = 0.1, alpha = 0.8) +
theme_ctokita() +
facet_grid(Model~n)
gg_behav_dist
# Plot behavioral distributions
gg_behav_dist <- ggplot(data = behav_analysis, aes(x = Task1, y = Task2)) +
geom_point(size = 0.1, alpha = 0.05) +
theme_ctokita() +
facet_grid(Model~n)
gg_behav_dist
run <- "Sigma0.05-Epsilon0-Beta1.1-Delta0.6-CHECK"
rm(list = ls())
source("scripts/util/__Util__MASTER.R")
p <- 1 #prob of interact
runs <- c("Sigma0.05-Epsilon0-Beta1.1-Delta0.6-CHECK",
# "Sigma0.05-Epsilon0-Beta1.1",
"Sigma0-Epsilon0.1-Beta1.1")
run_names <- c("Fixed", "Social")
interaction_rates <- lapply(1:length(runs), function(run) {
# Load social networks
files <- list.files(paste0("output/Rdata/_ProcessedData/Graphs/", runs[run], "/"), full.names = TRUE)
soc_networks <- list()
for (file in 1:length(files)) {
load(files[file])
soc_networks[[file]] <- listed_data
}
# Load threshold matrices
files <- list.files(paste0("output/Rdata/_ProcessedData/Thresh/", runs[run], "/"), full.names = TRUE)
thresh_data <- list()
for (file in 1:length(files)) {
load(files[file])
thresh_data[[file]] <- listed_data
}
# Loop through individual graphs
interaction_info <- lapply(1:length(soc_networks), function(i) {
# Get graphs
graphs <- soc_networks[[i]]
replicates <- length(graphs)
# For each each compute interaction matrix
# Get graph and make adjacency matrix
size_graph <- lapply(1:length(graphs), function(j) {
# Format: set diagonal, rescale, and make adj matrix
this_graph <- graphs[[j]]
diag(this_graph) <- NA
thresh <- as.data.frame(thresh_data[[i]][j])
thresh$ThreshBias <- thresh$Thresh1 - thresh$Thresh2
ratio <- order(thresh$ThreshBias)
# Create order by threshold ratio
this_graph <- this_graph[ratio, ratio]
colnames(this_graph) <- 1:nrow(this_graph)
rownames(this_graph) <- colnames(this_graph)
g <- graph.adjacency(adjmatrix = this_graph, weighted = T)
edgelist_graph <- as.data.frame(get.edgelist(g))
names(edgelist_graph) <- c("From", "To")
edgelist_graph$Weight <- E(g)$weight
edgelist_graph$Interaction <- paste0(edgelist_graph$From, "-", edgelist_graph$To)
# return
return(edgelist_graph)
})
#Calculate baseline probability of interaction
dimensions <- dim(graphs[[1]])
not_chosen <- 1 - (( 1 / (dimensions[1] - 1)) * p)
expected_random <-  1 - not_chosen^2
# Bind
all_edgelist <- do.call("rbind", size_graph)
#  Calcualte 99% CI interval of interaction rate
edgelist_sig <- all_edgelist %>%
group_by(From, To, Interaction) %>%
# filter(!is.na(Weight)) %>%
summarise(samp_mean = mean(Weight),
samp_sd = sd(Weight),
samples = length(Weight)) %>%
mutate(error = qt(0.975, df = samples-1) * samp_sd/sqrt(samples),
CI_low = samp_mean - error,
CI_high = samp_mean + error) %>%
mutate(Lower_check = CI_low > expected_random,
Higher_check = CI_high > expected_random)
# Determine if it is different than random
edgelist_sig <- as.data.frame(edgelist_sig)
edgelist_sig$DiffDirection <- 0
edgelist_sig$DiffDirection[edgelist_sig$Lower_check & edgelist_sig$Higher_check] <- 1
edgelist_sig$DiffDirection[edgelist_sig$Lower_check==FALSE & edgelist_sig$Higher_check==FALSE] <- -1
# Make graph
edgelist_sig <- edgelist_sig %>%
summarise(Nonrandom = sum(DiffDirection!=0),
HigherThanRandom = sum(DiffDirection == 1),
LowerThanRandom = sum(DiffDirection == -1),
TotalInteractions = n()) %>%
mutate(PercentNonRandom = Nonrandom / TotalInteractions,
PercentHigher = HigherThanRandom / TotalInteractions,
PercentLower = LowerThanRandom / TotalInteractions,
n = dimensions[1],
Model = run_names[run])
# Return
print(paste0(run_names[run], ": ", dimensions[1]))
return(edgelist_sig)
})
# Bind and return
interaction_info <- do.call("rbind", interaction_info)
return(interaction_info)
})
# Bind
interaction_data <- do.call('rbind', interaction_rates)
# Graph
gg_interactions <- ggplot(interaction_data, aes(x = n, y = PercentNonRandom,
colour = Model, group = Model, fill = Model)) +
geom_line(size = 0.4) +
geom_point(size = 0.8, shape = 21) +
scale_y_continuous(limits = c(0, 1)) +
scale_color_manual(name = "Threshold type",
values = c("#878787", "#4d4d4d")) +
scale_fill_manual(name = "Threshold type",
values = c("#ffffff", "#4d4d4d")) +
xlab(expression(paste("Group Size (", italic(n), ")"))) +
ylab("% Non-random interactions") +
# facet_grid(~Model) +
theme_ctokita() +
theme(aspect.ratio = 1,
# strip.background = element_blank(),
# strip.text = element_blank(),
legend.position = "none")
gg_interactions
p <- 1 #prob of interact
runs <- c("Sigma0.1-Epsilon0-Beta1.1-Delta0.6-CHECK",
# "Sigma0.05-Epsilon0-Beta1.1",
"Sigma0-Epsilon0.1-Beta1.1")
run_names <- c("Fixed", "Social")
interaction_rates <- lapply(1:length(runs), function(run) {
# Load social networks
files <- list.files(paste0("output/Rdata/_ProcessedData/Graphs/", runs[run], "/"), full.names = TRUE)
soc_networks <- list()
for (file in 1:length(files)) {
load(files[file])
soc_networks[[file]] <- listed_data
}
# Load threshold matrices
files <- list.files(paste0("output/Rdata/_ProcessedData/Thresh/", runs[run], "/"), full.names = TRUE)
thresh_data <- list()
for (file in 1:length(files)) {
load(files[file])
thresh_data[[file]] <- listed_data
}
# Loop through individual graphs
interaction_info <- lapply(1:length(soc_networks), function(i) {
# Get graphs
graphs <- soc_networks[[i]]
replicates <- length(graphs)
# For each each compute interaction matrix
# Get graph and make adjacency matrix
size_graph <- lapply(1:length(graphs), function(j) {
# Format: set diagonal, rescale, and make adj matrix
this_graph <- graphs[[j]]
diag(this_graph) <- NA
thresh <- as.data.frame(thresh_data[[i]][j])
thresh$ThreshBias <- thresh$Thresh1 - thresh$Thresh2
ratio <- order(thresh$ThreshBias)
# Create order by threshold ratio
this_graph <- this_graph[ratio, ratio]
colnames(this_graph) <- 1:nrow(this_graph)
rownames(this_graph) <- colnames(this_graph)
g <- graph.adjacency(adjmatrix = this_graph, weighted = T)
edgelist_graph <- as.data.frame(get.edgelist(g))
names(edgelist_graph) <- c("From", "To")
edgelist_graph$Weight <- E(g)$weight
edgelist_graph$Interaction <- paste0(edgelist_graph$From, "-", edgelist_graph$To)
# return
return(edgelist_graph)
})
#Calculate baseline probability of interaction
dimensions <- dim(graphs[[1]])
not_chosen <- 1 - (( 1 / (dimensions[1] - 1)) * p)
expected_random <-  1 - not_chosen^2
# Bind
all_edgelist <- do.call("rbind", size_graph)
#  Calcualte 99% CI interval of interaction rate
edgelist_sig <- all_edgelist %>%
group_by(From, To, Interaction) %>%
# filter(!is.na(Weight)) %>%
summarise(samp_mean = mean(Weight),
samp_sd = sd(Weight),
samples = length(Weight)) %>%
mutate(error = qt(0.975, df = samples-1) * samp_sd/sqrt(samples),
CI_low = samp_mean - error,
CI_high = samp_mean + error) %>%
mutate(Lower_check = CI_low > expected_random,
Higher_check = CI_high > expected_random)
# Determine if it is different than random
edgelist_sig <- as.data.frame(edgelist_sig)
edgelist_sig$DiffDirection <- 0
edgelist_sig$DiffDirection[edgelist_sig$Lower_check & edgelist_sig$Higher_check] <- 1
edgelist_sig$DiffDirection[edgelist_sig$Lower_check==FALSE & edgelist_sig$Higher_check==FALSE] <- -1
# Make graph
edgelist_sig <- edgelist_sig %>%
summarise(Nonrandom = sum(DiffDirection!=0),
HigherThanRandom = sum(DiffDirection == 1),
LowerThanRandom = sum(DiffDirection == -1),
TotalInteractions = n()) %>%
mutate(PercentNonRandom = Nonrandom / TotalInteractions,
PercentHigher = HigherThanRandom / TotalInteractions,
PercentLower = LowerThanRandom / TotalInteractions,
n = dimensions[1],
Model = run_names[run])
# Return
print(paste0(run_names[run], ": ", dimensions[1]))
return(edgelist_sig)
})
# Bind and return
interaction_info <- do.call("rbind", interaction_info)
return(interaction_info)
})
rm(list = ls())
source("scripts/util/__Util__MASTER.R")
library(RColorBrewer)
library(scales)
library(viridis)
library(ggridges)
run <- "Sigma0.05-Epsilon0-Beta1.1"
####################
# Load data
####################
load("output/Rdata/_ProcessedData/TaskDist/Sigma0-Epsilon0.1-Beta1.1.Rdata")
social_data <- compiled_data
social_data$Model <- "Social"
load("output/Rdata/_ProcessedData/TaskDist/Sigma0.05-Epsilon0-Beta1.1.Rdata")
fixed_data <- compiled_data
fixed_data$Model <- "Fixed"
behav_data <- rbind(social_data, fixed_data) %>%
mutate(Set = paste(sim, chunk, sep = "-"))
rm(compiled_data, social_data, fixed_data)
####################
#  Look at raw behavioral distributions
####################
behav_analysis <- behav_data %>%
filter(n %in% c(10, 25, 50, 90),
Set == "2-1")
# Plot behavioral distributions
gg_behav_dist <- ggplot(data = behav_analysis, aes(x = Task1, y = Task2)) +
geom_point(size = 0.1, alpha = 0.05) +
theme_ctokita() +
facet_grid(Model~n)
gg_behav_dist
####################
#  Look at raw behavioral distributions
####################
behav_analysis <- behav_data %>%
filter(n %in% c(10, 25, 50, 90))
# Plot behavioral distributions
gg_behav_dist <- ggplot(data = behav_analysis, aes(x = Task1, y = Task2)) +
geom_point(size = 0.1, alpha = 0.05) +
theme_ctokita() +
facet_grid(Model~n)
gg_behav_dist
# Plot behavioral distributions
gg_behav_dist <- ggplot(data = behav_analysis, aes(x = Task1, y = Task2)) +
geom_point(size = 0.1, alpha = 0.03) +
theme_ctokita() +
facet_grid(Model~n)
gg_behav_dist
# Plot behavioral distributions
gg_behav_dist <- ggplot(data = behav_analysis, aes(x = Task1, y = Task2)) +
geom_point(size = 0.1, alpha = 0.01) +
theme_ctokita() +
facet_grid(Model~n)
gg_behav_dist
rm(list = ls())
source("scripts/util/__Util__MASTER.R")
library(RColorBrewer)
library(scales)
library(viridis)
library(ggridges)
####################
# Load data
####################
load("output/Rdata/_ProcessedData/TaskDist/Sigma0-Epsilon0.1-Beta1.1.Rdata")
social_data <- compiled_data
social_data$Model <- "Social"
load("output/Rdata/_ProcessedData/TaskDist/Sigma0.05-Epsilon0-Beta1.1-Delta0.6-CHECK.Rdata")
fixed_data <- compiled_data
fixed_data$Model <- "Fixed"
behav_data <- rbind(social_data, fixed_data) %>%
mutate(Set = paste(sim, chunk, sep = "-"))
rm(compiled_data, social_data, fixed_data)
####################
#  Look at raw behavioral distributions
####################
behav_analysis <- behav_data %>%
filter(n %in% c(10, 25, 50, 90))
# Plot behavioral distributions
gg_behav_dist <- ggplot(data = behav_analysis, aes(x = Task1, y = Task2)) +
geom_point(size = 0.1, alpha = 0.01) +
theme_ctokita() +
facet_grid(Model~n)
gg_behav_dist
