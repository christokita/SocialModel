p              <- 1 #baseline probablity of initiating an interaction per time step
epsilon        <- 0.6 #relative weighting of social interactions for adjusting thresholds
beta           <- 1.1 #probability of interacting with individual in same state relative to others
####################
# Run ensemble simulation
####################
# Prep meta-lists for collection of group size simulations
groups_taskDist    <- list()
groups_taskTally   <- list()
groups_stim        <- list()
groups_thresh      <- list()
groups_entropy     <- list()
groups_thresh1Time <- list()
groups_thresh2Time <- list()
groups_graphs      <- list()
# Loop through group sizes
for (i in 1:length(Ns)) {
# Set group size
n <- Ns[i]
# Prep lists for collection of simulation outputs from this group size
ens_taskDist    <- list()
ens_taskTally   <- list()
ens_entropy     <- list()
ens_stim        <- list()
ens_thresh      <- list()
ens_thresh1Time <- list()
ens_thresh2Time <- list()
ens_graphs      <- list()
# Run Simulations
for (sim in 1:reps) {
####################
# Seed structures and intial matrices
####################
# Set initial probability matrix (P_g)
P_g <- matrix(data = rep(0, n * m), ncol = m)
# Seed task (external) stimuli
stimMat <- seed_stimuls(intitial_stim = InitialStim,
gens = gens)
# Seed internal thresholds
threshMat <- seed_thresholds(n = n,
m = m,
threshold_means = ThreshM,
threshold_sds = ThreshSD)
# Start task performance
X_g <- matrix(data = rep(0, length(P_g)), ncol = ncol(P_g))
# Create cumulative task performance matrix
X_tot <- X_g
# Create cumulative adjacency matrix
g_tot <-  matrix(data = rep(0, n * n), ncol = n)
colnames(g_tot) <- paste0("v-", 1:n)
rownames(g_tot) <- paste0("v-", 1:n)
# Prep lists for data collection within simulation
taskTally <- list()
thresh1time <- list()
thresh2time <- list()
thresh1time[[1]] <- threshMat[ ,1]
thresh2time[[1]] <- threshMat[ ,2]
####################
# Simulate individual run
####################
# Run simulation
for (t in 1:gens) {
# Current timestep is actually t+1 in this formulation, because first row is timestep 0
# Update stimuli
stimMat <- update_stim(stim_matrix = stimMat,
deltas = deltas,
alpha = alpha,
state_matrix = X_g,
time_step = t)
# Calculate task demand based on global stimuli
P_g <- calc_determ_thresh(time_step        = t + 1, # first row is generation 0
threshold_matrix = threshMat,
stimulus_matrix  = stimMat)
# Update task performance
X_g <- update_task_performance(task_probs   = P_g,
state_matrix = X_g,
quit_prob    = quitP)
# Update social network (previously this was before probability/task update)
g_adj <- temporalNetwork(X_sub_g = X_g,
prob_interact = p,
bias = beta)
g_tot <- g_tot + g_adj
# Adjust thresholds
threshMat <- adjust_thresholds_social_capped(social_network = g_adj,
threshold_matrix = threshMat,
state_matrix = X_g,
epsilon = epsilon,
threshold_max = thresh_max)
# Capture threshold values
thresh1time[[t + 1]] <- threshMat[,1]
thresh2time[[t + 1]] <- threshMat[,2]
# Update total task performance profile
X_tot <- X_tot + X_g
# Capture current task performance tally
tally <- matrix(c(t, colSums(X_g)), ncol = ncol(X_g) + 1)
colnames(tally) <- c("t", colnames(X_g))
taskTally[[t]] <- tally
}
####################
# Post run calculations
####################
# Bind together task tally
col_names <- colnames(taskTally[[1]])
taskTally <- matrix(unlist(taskTally),
ncol = length(taskTally[[1]]),
byrow = TRUE,
dimnames = list(c(NULL), c(col_names)))
# Calculate Entropy
entropy <- mutualEntropy(TotalStateMat = X_tot)
# Calculate total task distribution
totalTaskDist <- X_tot / gens
# Create tasktally table
stimMat <- cbind(stimMat, 0:(nrow(stimMat) - 1))
colnames(stimMat)[ncol(stimMat)] <- "t"
# Add total task distributions, entropy values, and graphs to lists
ens_taskDist[[sim]]    <- totalTaskDist
ens_entropy[[sim]]     <- entropy
ens_taskTally[[sim]]   <- taskTally
ens_stim[[sim]]        <- stimMat
ens_thresh[[sim]]      <- threshMat
ens_thresh1Time[[sim]] <- thresh1time
ens_thresh2Time[[sim]] <- thresh2time
ens_graphs[[sim]]      <- g_tot / gens
}
# Add to list of lists
groups_taskDist[[i]]    <- ens_taskDist
groups_taskTally[[i]]   <- ens_taskTally
groups_stim[[i]]        <- ens_stim
groups_thresh[[i]]      <- ens_thresh
groups_entropy[[i]]     <- ens_entropy
groups_thresh1Time[[i]] <- ens_thresh1Time
groups_thresh2Time[[i]] <- ens_thresh2Time
groups_graphs[[i]]      <- ens_graphs
}
thresh_time <- do.call('rbind', thresh1time)
thresh_time <- as.data.frame(thresh_time)
thresh_time <- thresh_time %>%
mutate(t = 1:nrow(.)) %>%
gather(., Id, Threshold, -t)
gg_threshtime_1000 <- ggplot(thresh_time, aes(x = t, y = Threshold, group = Id)) +
geom_line(size = 0.1, alpha = 0.15, colour = "#8bbeda") +
scale_x_continuous(name = expression(paste("Time step (", italic(t), ")")),
breaks = seq(0, 50000, 10000),
labels = c("", "10,000", "", "30,000", "", "50,000"),
expand = c(0, 0)) +
scale_y_continuous(name = expression(paste("Task 1 threshold (", italic(theta[i1,t]), ")")),
limits = c(0, 1200),
breaks = seq(0, 1200, 600),
label = comma) +
theme_ctokita() +
theme(axis.title.y = element_blank(),
axis.text.x = element_text(hjust = 0.7))
gg_threshtime_1000
rm(list = ls())
####################
# Source necessary scripts/libraries
####################
source("scripts/util/__Util__MASTER.R")
library(scales)
####################
# calculate epsilon* and beta* for n = 80 with infinite threshold limit
####################
# Let's assume all individuals are doing task 1 (or are inactive)
# Set parameters
tau <- 0.2
n <- 80
m <- 2
delta <- 0.8
beta <- seq(1, 1.25, 0.0001)
freq_activ <- delta
# freq_activ <- 1 / (1+tau)
n_1 <- freq_activ * n
beta_star_value <- (delta * n) / (delta * n - m)
# Calculate beta* and epsilon*
beta_star <- data.frame(epsilon = seq(0, 0.6, 0.01),
beta = rep(beta_star_value, length(seq(0, 0.6, 0.01))))
eps_star <- data.frame(beta = beta,
epsilon_inac = rep(NA, length(beta)),
epsilon_ac = rep(NA, length(beta)),
# epsilon_e11_e01_ratio = rep(NA, length(beta)),
epsilon_all = rep(NA, length(beta)))
for (i in 1:nrow(eps_star)) {
E_01 <- n_1 / (n_1 + (n - n_1)) +  n_1 * ( (1) / (beta[i] * (n_1 - 1) + (n - n_1)) )  # expected number of interaction partners performing task 1 if i is inactive
E_11 <- 2*beta[i]*(n_1 - 1) / (beta[i] * (n_1 - 1) + (n - n_1)) # expected number of interaction partners performing task 1 if i is task 1
eps_01 <- delta / E_01
eps_11 <- delta / E_11
eps_star$epsilon_inac[i] <- eps_01
eps_star$epsilon_ac[i] <- eps_11
eps_star$epsilon_all[i] <- delta / (tau/(1+tau) * E_01 + 1/(1+tau) * E_11)
}
eps_star$epsilon_all[eps_star$beta == 1.02]
ggplot(data = eps_star, aes(x = beta)) +
geom_line(aes(y = epsilon_all)) +
geom_line(aes(y = epsilon_inac), color = "lightblue") +
geom_line(aes(y = epsilon_ac), color = "grey80") +
theme_ctokita()
stimMat[1000,]
rm(list = ls())
source("scripts/util/__Util__MASTER.R")
betas <- seq(1, 1.25, 0.0001)
delta <- 0.8
nstar <- lapply(betas, function(beta) {
full_solution_nom <- (4*beta-delta-4*beta*delta+5*beta^2*delta+sqrt(16*beta^2-8*beta*delta+16*beta^2*delta-8*beta^3*delta+delta^2+8*beta*delta^2-18*beta^2*delta^2+8*beta^3*delta^2+beta^4*delta^2))
full_solution_denom <- 2*(-2*delta+2*beta*delta+delta^2-2*beta*delta^2+beta^2*delta^2)
full_solution <- full_solution_nom / full_solution_denom
simp_solution <- 2*beta / (delta * (beta-1))
to_return <- data.frame(beta = beta, nstar_simp = simp_solution, nstar_full = full_solution)
})
nstar <- do.call('rbind', nstar)
nstar_melt <- nstar %>%
melt(id.vars = "beta")
# Plot
gg_nstar_comp <- ggplot(nstar_melt, aes(x = beta, group = variable, color = variable)) +
geom_line(aes(y = value), size = 0.3) +
ylab("n*") +
xlab(expression(paste("Interaction bias (", beta, ")"))) +
scale_y_continuous(limits = c(0, 30)) +
scale_color_manual(name = "Solution", values = c("#0d75ff", "#d60036"), labels = c("Simplified", "Full")) +
theme_ctokita() +
theme(aspect.ratio = 1,
legend.position = "right")
gg_nstar_comp
# Plot
gg_nstar_comp <- ggplot(nstar_melt, aes(x = beta, group = variable, color = variable)) +
geom_line(aes(y = value), size = 0.3) +
ylab("n*") +
xlab(expression(paste("Interaction bias (", beta, ")"))) +
scale_y_continuous(limits = c(0, 50)) +
scale_color_manual(name = "Solution", values = c("#0d75ff", "#d60036"), labels = c("Simplified", "Full")) +
theme_ctokita() +
theme(aspect.ratio = 1,
legend.position = "right")
gg_nstar_comp
# Plot
gg_nstar_comp <- ggplot(nstar_melt, aes(x = beta, group = variable, color = variable)) +
geom_line(aes(y = value), size = 0.3) +
ylab("n*") +
xlab(expression(paste("Interaction bias (", beta, ")"))) +
scale_y_continuous(limits = c(0, 100)) +
scale_color_manual(name = "Solution", values = c("#0d75ff", "#d60036"), labels = c("Simplified", "Full")) +
theme_ctokita() +
theme(aspect.ratio = 1,
legend.position = "right")
gg_nstar_comp
# Plot
gg_nstar_comp <- ggplot(nstar_melt, aes(x = beta, group = variable, color = variable)) +
geom_line(aes(y = value), size = 0.3) +
ylab("n*") +
xlab(expression(paste("Interaction bias (", beta, ")"))) +
scale_y_continuous(limits = c(0, 800)) +
scale_color_manual(name = "Solution", values = c("#0d75ff", "#d60036"), labels = c("Simplified", "Full")) +
theme_ctokita() +
theme(aspect.ratio = 1,
legend.position = "right")
# Plot
gg_nstar_comp <- ggplot(nstar_melt, aes(x = beta, group = variable, color = variable)) +
geom_line(aes(y = value), size = 0.3) +
ylab("n*") +
xlab(expression(paste("Interaction bias (", beta, ")"))) +
scale_y_continuous(limits = c(0, 80)) +
scale_color_manual(name = "Solution", values = c("#0d75ff", "#d60036"), labels = c("Simplified", "Full")) +
theme_ctokita() +
theme(aspect.ratio = 1,
legend.position = "right")
gg_nstar_comp
ggsave(gg_nstar_comp, file = "output/AnalyticalResults/FullVsSimplifiedSolution.png", dpi = 400, width = 95, height = 65, units = "mm")
rm(list = ls())
source("scripts/util/__Util__MASTER.R")
directory_path <- "output/Rdata/long_sims/n80-Sigma0-Beta1.1_EpsSweep-LongRun/"
output_path <- "output/Rdata/_ProcessedData/_LongSims/"
run_info <- gsub("^.*(Sigma.*)/$", "\\1", directory_path, perl = TRUE)
####################
# Create folders
####################
# Get names of folders
folders <- list.files(directory_path)
output_folders <- list.files(output_path)
# Create folders for those not existing in processed data
missing_folders <- folders[!folders %in% output_folders]
for (missing_folder in missing_folders) {
dir.create(paste0(output_path, missing_folder))
}
# Divide up folders into those where bound dataframes will be made
# and those where compiled lists will be made (for the sake of memory)
bind_folders <- folders[folders %in% c("Entropy", "TaskDist")]
list_folders <- folders[folders %in% c("Graphs", "Thresh", "Stim")]
####################
# Bind and save entropy
####################
files <- list.files(paste0(directory_path, "Entropy"), full.names = T)
entropy_data <- list()
for (i in 1:length(files)) {
file <- files[i]
sim_number <- as.numeric(gsub(file, pattern = ".*Sim_([0-9]+).Rdata", replacement = "\\1", perl = T))
load(file)
entropy <- as.data.frame(entropy)
entropy$sim <- sim_number
entropy_data[[i]] <- entropy
}
entropy_data <- do.call("rbind", entropy_data)
save(entropy_data, file = paste0(output_path, "/Entropy/", run_info, ".Rdata"))
####################
# Bind and save task distributions
####################
files <- list.files(paste0(directory_path, "TaskDist"), full.names = T)
taskdist_data <- list()
for (i in 1:length(files)) {
file <- files[i]
sim_number <- as.numeric(gsub(file, pattern = ".*Sim_([0-9]+).Rdata", replacement = "\\1", perl = T))
load(file)
totalTaskDist <- as.data.frame(totalTaskDist)
totalTaskDist$sim <- sim_number
taskdist_data[[i]] <- totalTaskDist
}
taskdist_data <- do.call("rbind", taskdist_data)
save(taskdist_data, file = paste0(output_path, "/TaskDist/", run_info, ".Rdata"))
####################
# Bind and save thresh data
####################
files <- list.files(paste0(directory_path, "Thresh"), full.names = T)
thresh_data <- list()
for (i in 1:length(files)) {
file <- files[i]
sim_number <- as.numeric(gsub(file, pattern = ".*Sim_([0-9]+).Rdata", replacement = "\\1", perl = T))
load(file)
threshMat <- as.data.frame(threshMat)
threshMat$sim <- sim_number
thresh_data[[i]] <- threshMat
}
save(thresh_data, file = paste0(output_path, "/Thresh/", run_info, ".Rdata"))
####################
# Bind and save task distributions
####################
files <- list.files(paste0(directory_path, "TaskDist"), full.names = T)
taskdist_data <- list()
for (i in 1:length(files)) {
file <- files[i]
sim_number <- as.numeric(gsub(file, pattern = ".*Sim_([0-9]+).Rdata", replacement = "\\1", perl = T))
load(file)
totalTaskDist <- as.data.frame(totalTaskDist)
totalTaskDist$sim <- sim_number
taskdist_data[[i]] <- totalTaskDist
}
taskdist_data <- do.call("rbind", taskdist_data)
save(taskdist_data, file = paste0(output_path, "/TaskDist/", run_info, ".Rdata"))
####################
# Bind and save graphs
####################
files <- list.files(paste0(directory_path, "Graphs"), full.names = T)
graphs_data <- list()
for (i in 1:length(files)) {
file <- files[i]
sim_number <- as.numeric(gsub(file, pattern = ".*Sim_([0-9]+).Rdata", replacement = "\\1", perl = T))
load(file)
graphs_data[[i]] <- g_tot
}
save(graphs_data, file = paste0(output_path, "/Graphs/", run_info, ".Rdata"))
####################
# Bind and save stim data
####################
files <- list.files(paste0(directory_path, "Stim"), full.names = T)
stim_data <- list()
for (i in 1:length(files)) {
file <- files[i]
sim_number <- as.numeric(gsub(file, pattern = ".*Sim_([0-9]+).Rdata", replacement = "\\1", perl = T))
load(file)
stim_data[[i]] <- stimMat
}
save(stim_data, file = paste0(output_path, "/Stim/", run_info, ".Rdata"))
rm(list = ls())
source("scripts/util/__Util__MASTER.R")
directory_path <- "output/Rdata/long_sims/n80-Sigma0-Beta1.1_EpsSweep-LongRun/"
output_path <- "output/Rdata/_ProcessedData/_LongSims/"
run_info <- gsub("^.*(Sigma.*)/$", "\\1", directory_path, perl = TRUE)
####################
# Create folders
####################
# Get names of folders
folders <- list.files(directory_path)
output_folders <- list.files(output_path)
# Create folders for those not existing in processed data
missing_folders <- folders[!folders %in% output_folders]
for (missing_folder in missing_folders) {
dir.create(paste0(output_path, missing_folder))
}
# Divide up folders into those where bound dataframes will be made
# and those where compiled lists will be made (for the sake of memory)
bind_folders <- folders[folders %in% c("Entropy", "TaskDist")]
list_folders <- folders[folders %in% c("Graphs", "Thresh", "Stim")]
####################
# Bind and save entropy
####################
files <- list.files(paste0(directory_path, "Entropy"), full.names = T)
entropy_data <- list()
for (i in 1:length(files)) {
file <- files[i]
sim_number <- as.numeric(gsub(file, pattern = ".*Sim_([0-9]+).Rdata", replacement = "\\1", perl = T))
load(file)
entropy <- as.data.frame(entropy)
entropy$sim <- sim_number
entropy_data[[i]] <- entropy
}
rm(list = ls())
source("scripts/util/__Util__MASTER.R")
library(RColorBrewer)
library(scales)
directory_path <- "output/Rdata/n80-Sigma0-Beta1.1_EpsSweep-LongRun/"
output_path <- "output/Rdata/_ProcessedData/"
run_info <- gsub("^.*(Sigma.*)/$", "\\1", directory_path, perl = TRUE)
run_info
source('~/Documents/Research/Tarnita Lab/Social Interaction DOL/SocialModel/scripts/2b_Process_ClusterSimData.R', echo=TRUE)
source('~/Documents/Research/Tarnita Lab/Social Interaction DOL/SocialModel/scripts/2b_Process_ClusterSimData.R', echo=TRUE)
load('output/Rdata/_ProcessedData/Entropy/Sigma0-Beta1.1_EpsSweep-NoThreshLimit-LongRun.Rdata')
high_thresh <- compiled_data %>%
mutate(Model = "high_thresh") %>%
group_by(Model, epsilon, beta) %>%
summarise(Mean = mean(Dind),
SD = sd(Dind)) %>%
as.data.frame() %>%
mutate(epsilon = round(epsilon, digits = 3))
load('output/Rdata/_ProcessedData/Entropy/Sigma0-Beta1.1_EpsSweep-LongRun.Rdata')
normal_thresh <- entropy %>%
mutate(Model = "normal_thresh") %>%
filter(beta == 1.1) %>%
select(Model, epsilon, beta, Dind_mean, Dind_SD)
normal_thresh <- compiled_data %>%
mutate(Model = "normal_thresh") %>%
filter(beta == 1.1) %>%
select(Model, epsilon, beta, Dind_mean, Dind_SD)
normal_thresh <- compiled_data %>%
mutate(Model = "normal_thresh") %>%
group_by(Model, epsilon, beta) %>%
summarise(Mean = mean(Dind),
SD = sd(Dind)) %>%
as.data.frame() %>%
mutate(epsilon = round(epsilon, digits = 3))
eps_values <- unique(normal_thresh$epsilon)
entropy_data <- rbind(high_thresh, normal_thresh)
entropy_data <- entropy_data %>%
filter(epsilon %in% eps_values)
####################
# Plot entropy plots
####################
gg_comp <- ggplot(entropy_data, aes(x = epsilon, y = Mean, group = Model, color = Model)) +
# geom_vline(xintercept = 0.5659957, size = 0.3, linetype = "dashed") + #analytical result for epsilon*
geom_vline(xintercept = 0.4969125, size = 0.3, linetype = "dashed", color = "grey40") + #analytical result for epsilon*
geom_vline(xintercept = 0, size = 0.3, linetype = "dashed", color = "grey40") + #analytical result for epsilon*
geom_errorbar(aes(ymin = ifelse((Mean - SD) > 0, Mean - SD, 0), ymax = Mean + SD),
width = 0,
size = 0.3) +
geom_point(aes(y = Mean),
size = 0.8) +
theme_classic() +
xlab(expression(paste("Social influence (", italic(epsilon), ")"))) +
ylab(expression(paste("Division of labor (", italic(D[indiv]), ")"))) +
scale_color_manual(name = "Thresh. limits",
values = c("#a6cee3", "#1f78b4"),
labels = c(expression(paste("[0, ", infinity, ")")), "[0, 100]")) +
# ggtitle(expression(paste(italic(epsilon), "= 0.4, ", italic(beta), "= 1.1"))) +
scale_x_continuous(breaks = seq(0, 0.6, 0.1)) +
theme(title = element_text(size = 6),
axis.text = element_text(colour = "black", size = 6),
axis.title = element_text(size = 7, face = "italic"),
legend.position = c(0.3, 0.2),
legend.title = element_text(size = 6,
face = "bold",
hjust = 5),
legend.text = element_text(size = 6),
legend.key.height = unit(2, "mm"),
legend.key.width = unit(3, "mm"),
legend.background = element_blank(),
axis.ticks = element_line(size = 0.3, color = "black"),
axis.line = element_line(size = 0.3, color = "black"),
aspect.ratio = 1)
gg_comp
####################
# Plot entropy plots
####################
gg_comp_long <- ggplot(entropy_data, aes(x = epsilon, y = Mean, group = Model, color = Model)) +
# geom_vline(xintercept = 0.5659957, size = 0.3, linetype = "dashed") + #analytical result for epsilon*
geom_vline(xintercept = 0.4969125, size = 0.3, linetype = "dashed", color = "grey40") + #analytical result for epsilon*
geom_vline(xintercept = 0, size = 0.3, linetype = "dashed", color = "grey40") + #analytical result for epsilon*
geom_errorbar(aes(ymin = ifelse((Mean - SD) > 0, Mean - SD, 0), ymax = Mean + SD),
width = 0,
size = 0.3) +
geom_point(aes(y = Mean),
size = 0.8) +
theme_classic() +
xlab(expression(paste("Social influence (", italic(epsilon), ")"))) +
ylab(expression(paste("Division of labor (", italic(D[indiv]), ")"))) +
scale_color_manual(name = "Thresh. limits",
values = c("#a6cee3", "#1f78b4"),
labels = c(expression(paste("[0, ", infinity, ")")), "[0, 100]")) +
# ggtitle(expression(paste(italic(epsilon), "= 0.4, ", italic(beta), "= 1.1"))) +
scale_x_continuous(breaks = seq(0, 0.6, 0.1)) +
theme(title = element_text(size = 6),
axis.text = element_text(colour = "black", size = 6),
axis.title = element_text(size = 7, face = "italic"),
legend.position = c(0.3, 0.2),
legend.title = element_text(size = 6,
face = "bold",
hjust = 5),
legend.text = element_text(size = 6),
legend.key.height = unit(2, "mm"),
legend.key.width = unit(3, "mm"),
legend.background = element_blank(),
axis.ticks = element_line(size = 0.3, color = "black"),
axis.line = element_line(size = 0.3, color = "black"),
aspect.ratio = 1)
gg_comp_long
ggsave(gg_comp_long, file = "output/SpecializationPlots/ThresholdLimitComparison_long.png", height = 45, width = 45, units = "mm")
ggsave(gg_comp_long, file = "output/SpecializationPlots/ThresholdLimitComparison_long.svg", height = 45, width = 45, units = "mm")
