{
    "collab_server" : "",
    "contents" : "################################################################################\n#\n# Model incorporating both thresholds and network dynamics\n#\n################################################################################\n\nrm(list = ls())\nsource(\"scripts/__Util__MASTER.R\")\n\n\n####################\n# Set global variables\n####################\n# Initial paramters: Free to change\n# Base parameters\nNs             <- c(100) #vector of number of individuals to simulate\nm              <- 2 #number of tasks\ngens           <- 10000 #number of generations to run simulation \ncorrStep       <- 200 #number of time steps for calculation of correlation \nreps           <- 1 #number of replications per simulation (for ensemble)\n\n# Threshold Parameters\nThreshM        <- rep(10, m) #population threshold means \nThreshSD       <- ThreshM * 0.01 #population threshold standard deviations\nInitialStim    <- rep(0, m) #intital vector of stimuli\ndeltas         <- rep(0.6, m) #vector of stimuli increase rates  \nalpha          <- m #efficiency of task performance\nquitP          <- 0.2 #probability of quitting task once active\n\n# Social Network Parameters\nepsilon        <- 0.01 #relative weighting of social interactions for lowering thresholds #0.01 = epsilon = phi\nphi            <- 0.01 #default forgetting rate of thresholds\np              <- 0.1 #probability of interacting with individual in other states\nq              <- 1.1 #probability of interacting with individual in same state relative to others\n\n\n\n####################\n# Run simulation multiple times\n####################\n# Prep meta-lists for collection of group size simulations\ngroups_taskDist  <- list()\ngroups_taskCorr  <- list()\ngroups_taskStep  <- list()\ngroups_taskTally <- list()\ngroups_stim      <- list()\ngroups_thresh    <- list()\ngroups_entropy   <- list()\ngroups_graphs    <- list()\n\n# Loop through group sizes\nfor (i in 1:length(Ns)) {\n  # Set group size\n  n <- Ns[i]\n  \n  # Prep lists for collection of simulation outputs\n  ens_taskDist  <- list()\n  ens_taskCorr  <- list()\n  ens_taskStep  <- list()\n  ens_taskTally <- list()\n  ens_entropy   <- list()\n  ens_stim      <- list()\n  ens_thresh    <- list()\n  ens_graphs    <- list()\n  \n  # Run Simulations\n  for (sim in 1:reps) {\n    \n    ####################\n    # Seed structures and intial matrices\n    ####################\n\n    # Set initial probability matrix (P_g)\n    P_g <- matrix(data = rep(0, n * m), ncol = m)\n    \n    # Seed task (external) stimuli\n    stimMat <- seedStimuls(InitialSVector = InitialStim, \n                           gens = gens)\n    \n    # Seed internal thresholds\n    threshMat <- seedThresholds(n = n, \n                                m = m, \n                                ThresholdMeans = ThreshM, \n                                ThresholdSDs = ThreshSD)\n    \n    # Start task performance\n    X_g <- matrix(data = rep(0, length(P_g)), ncol = ncol(P_g))\n    \n    # Create cumulative task performance matrix\n    X_tot <- X_g\n    \n    # Create cumulative adjacency matrix\n    g_tot <-  matrix(data = rep(0, n * n), ncol = n)\n    colnames(g_tot) <- paste0(\"v-\", 1:n)\n    rownames(g_tot) <- paste0(\"v-\", 1:n)\n    \n    # Prep correlation step matrix\n    X_prev <- matrix(data = rep(0, n * m), ncol = m)\n    X_prevTot <- matrix(data = rep(0, n * m), ncol = m)\n    taskCorr <- list()\n    taskStep <- list()\n    taskTally <- list()\n    \n    # Prep correlation tracking matrix\n    thresh1time <- list()\n    thresh2time <- list()\n    thresh1time[[1]] <- threshMat[,1]\n    thresh2time[[2]] <- threshMat[,2]\n    \n    ####################\n    # Simulate\n    ####################\n    # Run simulation\n    for (t in 1:gens) {\n      # Update stimuli\n      for (j in 1:ncol(stimMat)) {\n        # update stim\n        stimMat[t + 1, j] <- globalStimUpdate(stimulus = stimMat[t, j],\n                                              delta = deltas[j], \n                                              alpha = alpha, \n                                              Ni = sum(X_g[ , j]), \n                                              n = n)\n      }\n      # Update social network\n      g_adj <- temporalNetwork(X_sub_g = X_g,\n                               p = p,\n                               bias = q)\n      g_tot <- g_tot + g_adj\n      # Calculate task demand based on global stimuli\n      P_g <- calcThresholdDetermMat(TimeStep = t + 1, # first row is generation 0\n                                    ThresholdMatrix = threshMat, \n                                    StimulusMatrix = stimMat)\n      # Update task performance\n      X_g <- updateTaskPerformance(P_sub_g    = P_g,\n                                   TaskMat    = X_g,\n                                   QuitProb   = quitP)\n      # Adjust thresholds\n      threshMat <- adjustThresholdsSocial(SocialNetwork = g_adj,\n                                          ThresholdMatrix = threshMat, \n                                          X_sub_g = X_g, \n                                          epsilon = epsilon, \n                                          phi = phi)\n      thresh1time[[t + 1]] <- threshMat[,1]\n      thresh2time[[t + 1]] <- threshMat[,2]\n      \n      \n      # Capture current task performance tally\n      tally <- matrix(c(t, colSums(X_g)), ncol = ncol(X_g) + 1)\n      colnames(tally) <- c(\"t\", colnames(X_g))\n      tally <- transform(tally, Inactive = n - sum(X_g), n = n, replicate = sim)\n      taskTally[[t]] <- tally\n      \n      # Update total task performance profile\n      X_tot <- X_tot + X_g\n      \n      # Create time step for correlation\n      if (t %% corrStep == 0) {\n        # Get tasks performance in correlation step\n        X_step <- X_tot - X_prevTot\n        # Add to ensemble list of task steps\n        taskStep[[t / corrStep]] <- X_step\n        # Calculate rank correlation if it is not the first step\n        if(sum(X_prev) != 0) {\n          # Normalize\n          stepNorm <- X_step / rowSums(X_step)\n          prevNorm <- X_prev / rowSums(X_prev)\n          # Calculate ranks\n          step_ranks <- calculateTaskRank(TaskStepMat = X_step)\n          prev_ranks <- calculateTaskRank(TaskStepMat = X_prev)\n          # Calculate Correlation\n          rankCorr <- cor(prev_ranks, step_ranks, method = \"spearman\")\n          # Put in list\n          taskCorr[[(t / corrStep) - 1]] <- diag(rankCorr)\n          names(taskCorr)[(t / corrStep) - 1] <- paste0(\"Gen\", t)\n        }\n        # Update previous step total matrix\n        X_prevTot <- X_tot\n        # Update previous step total matrix\n        X_prev <- X_step\n      }\n    }\n    \n    # Calculate Entropy\n    entropy <- mutualEntropy(TotalStateMat = X_tot)\n    entropy <- transform(entropy, n = n, replicate = sim)\n    \n    # Calculate total task distribution\n    # totalTaskDist <- X_tot / rowSums(X_tot)\n    totalTaskDist <- X_tot / gens\n    totalTaskDist <- transform(totalTaskDist, Inactive = gens - rowSums(X_tot), n = n, replicate = sim)\n    \n    # Create tasktally table\n    taskTally <- do.call(\"rbind\", taskTally)\n    \n    # Create tasktally table\n    stimMat <- transform(stimMat, n = n, replicate = sim)\n    \n    # Create tasktally table\n    taskCorr <- transform(taskCorr, replicate = sim)\n    \n    # Add total task distributions, entropy values, and graphs to lists\n    ens_taskDist[[sim]]  <- totalTaskDist\n    ens_entropy[[sim]]   <- entropy\n    ens_taskCorr[[sim]]  <- taskCorr\n    ens_taskTally[[sim]] <- taskTally\n    ens_taskStep[[sim]]  <- taskStep\n    ens_stim[[sim]]      <- stimMat\n    ens_thresh[[sim]]    <- threshMat \n    ens_graphs[[sim]]    <- g_tot / gens\n    \n    # Print simulation completed\n    print(paste0(\"DONE: N = \", n, \", Simulation \", sim))\n  }\n  \n  # Calculate mean correlation for each n\n  runCorrs <- lapply(ens_taskCorr, function(x) {\n    # Unlist\n    runs <- do.call(\"rbind\", x)\n    replicate <- runs[nrow(runs), ]\n    replicate <- unique(replicate)\n    runs <- runs[-nrow(runs), ]\n    # Calculate mean\n    runMean <- matrix(data = rep(NA, m), ncol =  m)\n    for (column in 1:m) {\n      runMean[ , column] <- mean(runs[ , column], na.rm = TRUE)\n    }\n    runMean <- cbind(runMean, replicate)\n    colnames(runMean) <- c(paste0(\"Task\", 1:m), \"replicate\")\n    return(runMean)\n  })\n  runCorrs <- do.call(\"rbind\", runCorrs)\n  runCorrs <- transform(runCorrs, n = n)\n  \n  # Add to list of lists\n  groups_taskDist[[i]]  <- ens_taskDist\n  groups_taskCorr[[i]]  <- runCorrs\n  groups_taskStep[[i]]  <- ens_taskStep\n  groups_taskTally[[i]] <- ens_taskTally\n  groups_stim[[i]]      <- ens_stim\n  groups_thresh[[i]]    <- ens_thresh\n  groups_entropy[[i]]   <- ens_entropy\n  groups_graphs[[i]]    <- ens_graphs\n  \n}\n\n# trim out correlations for group size 1\nif(1 %in% Ns) {\n  groups_taskCorr <- groups_taskCorr[-1]\n}\n\nlibrary(RColorBrewer)\nlibrary(scales)\nlibrary(tidyr)\nlibrary(ggthemes)\n\nthresh1time <- do.call(\"rbind\", thresh1time)\nrow.names(thresh1time) <- NULL\nthresh1time <- as.data.frame(thresh1time)\nthresh1time <- thresh1time %>% \n  mutate(t = 0:(nrow(.)-1)) %>% \n  gather(\"Id\", \"Threshold\", 1:100)\n\nthreshMat <- threshMat %>% \n  as.data.frame(.) %>% \n  mutate(ThreshRatio = log(Thresh1 / Thresh2),\n         Id = row.names(.)) %>% \n  select(-Thresh1, -Thresh2)\n\nthresh1time <- merge(thresh1time, threshMat, by = \"Id\")\nthresh1time$ThreshRatio[thresh1time$ThreshRatio > 10] <- 10\nthresh1time$ThreshRatio[thresh1time$ThreshRatio < -10] <- -10\n\n\n# base_breaks_x <- function(x){\n#   b <- pretty(x)\n#   adjust_for_ticks <- max(b) * 0.0025\n#   d <- data.frame(y=-Inf, yend=-Inf, x=min(b) - adjust_for_ticks, xend=max(b) + adjust_for_ticks)\n#   list(geom_segment(data=d, aes(x=x, y=y, xend=xend, yend=yend),size = 1, inherit.aes=FALSE),\n#        scale_x_continuous(breaks=b))\n# }\n# base_breaks_y <- function(x){\n#   b <- pretty(x)\n#   adjust_for_ticks <- max(b) * 0.0025\n#   d <- data.frame(x = -Inf, xend = -Inf, y=min(b) - adjust_for_ticks, yend = max(b) + adjust_for_ticks)\n#   list(geom_segment(data=d, aes(x = x, y = y, xend = xend, yend = yend), size = 1, inherit.aes = FALSE),\n#        scale_y_continuous(breaks=b))\n# }\n# \n# test <- thresh1time[thresh1time$Id %in% c(\"v-22\", \"v-20\", \"v-25\", \"v-40\"),]\n# gg_thresh <- ggplot(data = thresh1time, \n#                     aes(x = t, y = Threshold)) +\n#   theme_bw(base_size = 10) +\n#   geom_line(aes(group = Id, colour = ThreshRatio), size = 0.5) +\n#   scale_colour_gradient2(name = \"ln(Threshold Ratio)\",\n#                          high = \"#d7191c\",\n#                          mid = \"#cecece\", \n#                          low = \"#2c7bb6\", \n#                          midpoint = 0, \n#                          limits = c(-2, 2),\n#                          oob = squish) +\n#   base_breaks_x(thresh1time$t) +\n#   base_breaks_y(thresh1time$Threshold) +\n#   theme(aspect.ratio = 1,\n#         panel.border = element_blank(),\n#         panel.grid.major = element_blank(),\n#         panel.grid.minor = element_blank(),\n#         legend.position = \"none\",\n#         axis.ticks.length = unit(4, \"pt\"),\n#         axis.text = element_text(color = \"black\"))\n# gg_thresh\n\n\ngg_thresh <- ggplot(data = thresh1time, \n                    aes(x = t, y = Threshold)) +\n  theme_classic(base_size = 10) +\n  geom_line(aes(group = Id, colour = ThreshRatio), size = 0.5) +\n  scale_colour_gradient2(name = \"ln(Threshold Ratio)\",\n                         high = \"#d7191c\",\n                         mid = \"#cecece\", \n                         low = \"#2c7bb6\", \n                         midpoint = 0, \n                         limits = c(-2, 2),\n                         oob = squish) +\n  scale_y_continuous(limits = c(0, 25), breaks = seq(0,25, 5)) +\n  theme(aspect.ratio = 1,\n        panel.border = element_blank(),\n        panel.grid.major = element_blank(),\n        panel.grid.minor = element_blank(),\n        legend.position = \"none\",\n        axis.ticks.length = unit(4, \"pt\"),\n        axis.text = element_text(color = \"black\"))\ngg_thresh\n\nggsave(\"output/ThresholdTime/Size100.png\", scale = 0.6, dpi = 600)\n",
    "created" : 1512153390492.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "358784458",
    "id" : "A45C740C",
    "lastKnownWriteTime" : 1512259586,
    "last_content_update" : 1512259586367,
    "path" : "~/Documents/Research/Tarnita Lab/Social Interaction DOL/SocialModel/scripts/1_SocThreshModel_TrackThresh.R",
    "project_path" : "scripts/1_SocThreshModel_TrackThresh.R",
    "properties" : {
    },
    "relative_order" : 6,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}